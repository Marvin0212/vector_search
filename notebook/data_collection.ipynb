{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "Total healthcare facility names retrieved: 63837\n",
      "Total unique healthcare facility names after filtering: 23450\n",
      "Total person name entries removed: 40387\n"
     ]
    }
   ],
   "source": [
    "import overpy\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Initialize the Overpass API\n",
    "api = overpy.Overpass()  # Read Only connection to OpenStreetMap\n",
    "\n",
    "# Load the SpaCy German model for NER\n",
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "\n",
    "# Function to modify name by appending specialty\n",
    "def modify_name(name, speciality):\n",
    "    # Process speciality to replace ';' with ' / '\n",
    "    if speciality:\n",
    "        speciality = speciality.replace(';', ' / ')\n",
    "        # Append the healthcare:speciality at the end with '/'\n",
    "        modified_name = name + ' / ' + speciality\n",
    "    else:\n",
    "        modified_name = name\n",
    "    return modified_name\n",
    "\n",
    "# Overpass QL query to get all relevant healthcare facilities in Germany\n",
    "overpass_query = \"\"\"\n",
    "[out:json][timeout:180];\n",
    "area[\"ISO3166-1\"=\"DE\"][admin_level=2];\n",
    "(\n",
    "  // Healthcare facilities\n",
    "  node[\"healthcare\"](area);\n",
    "  way[\"healthcare\"](area);\n",
    "  relation[\"healthcare\"](area);\n",
    ");\n",
    "out body;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Execute the Overpass query\n",
    "    result = api.query(overpass_query)\n",
    "\n",
    "    # Initialize sets to store unique names\n",
    "    all_facility_names = set()\n",
    "    filtered_facility_names = set()\n",
    "    person_names_removed = set()\n",
    "\n",
    "    # Function to process an element and extract both the original name and speciality\n",
    "    def process_element(element):\n",
    "        # Get the \"name\" tag of the element\n",
    "        name = element.tags.get(\"name\")\n",
    "        # Check if a name exists\n",
    "        if name:\n",
    "            name = name.strip()  # Remove any leading or trailing whitespace\n",
    "            if name and name.lower() != \"no name\":\n",
    "                # Get the \"healthcare:speciality\" tag, which provides specialty info\n",
    "                speciality = element.tags.get(\"healthcare:speciality\")\n",
    "                # Clean up the speciality if it exists, otherwise set it to an empty string\n",
    "                if speciality:\n",
    "                    speciality = speciality.strip()  # Remove any whitespace around the speciality\n",
    "                else:\n",
    "                    speciality = ''  # Default to an empty string if there's no speciality\n",
    "                return name, speciality  # Return both name and speciality\n",
    "        # Return None, None if there's no valid name\n",
    "        return None, None\n",
    "\n",
    "    # Function to filter out person names\n",
    "    def filter_person_names(name):\n",
    "        doc = nlp(name)\n",
    "        # Check if any entity in the name is labeled as PERSON with Spacy\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PER\":\n",
    "                return False  # It's a person name\n",
    "        return True  # It's a facility name\n",
    "\n",
    "    # Combine nodes, ways, and relations into a single list for easier processing\n",
    "    elements = result.nodes + result.ways + result.relations\n",
    "\n",
    "    # Process each element (each healthcare facility) individually\n",
    "    for element in elements:\n",
    "        # Extract the original name and speciality\n",
    "        original_name, speciality = process_element(element)\n",
    "        \n",
    "        # Only proceed if a valid name was found\n",
    "        if original_name:\n",
    "            modified_name = modify_name(original_name, speciality)\n",
    "            all_facility_names.add(modified_name)\n",
    "        \n",
    "            # Check if the name appears to be a facility, not a person's name\n",
    "            if filter_person_names(original_name):\n",
    "                # If it's a facility name, add it to the filtered set\n",
    "                filtered_facility_names.add(modified_name)\n",
    "            else:\n",
    "                person_names_removed.add(modified_name)\n",
    "\n",
    "    # Save all facility names to a text file\n",
    "    all_output_file = './data/OpenStreetMap_data/all_healthcare_facilities.txt'\n",
    "    with open(all_output_file, 'w', encoding='utf-8') as f:\n",
    "        for name in sorted(all_facility_names):\n",
    "            f.write(name + '\\n')\n",
    "\n",
    "    # Save the modified filtered facility names to a text file\n",
    "    modified_filtered_output_file = './data/OpenStreetMap_data/filtered_healthcare_facilities.txt'\n",
    "    with open(modified_filtered_output_file, 'w', encoding='utf-8') as f:\n",
    "        for name in filtered_facility_names:\n",
    "            f.write(name + '\\n')\n",
    "\n",
    "    # Save the person names that were removed to a separate text file\n",
    "    person_removed_file = './data/OpenStreetMap_data/person_names_removed.txt'\n",
    "    with open(person_removed_file, 'w', encoding='utf-8') as f:\n",
    "        for name in sorted(person_names_removed):\n",
    "            f.write(name + '\\n')\n",
    "\n",
    "    # Compare the two lists and report counts\n",
    "    total_all = len(all_facility_names)\n",
    "    total_filtered = len(filtered_facility_names)\n",
    "    total_removed = len(person_names_removed)\n",
    "\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(f\"Total healthcare facility names retrieved: {total_all}\")\n",
    "    print(f\"Total unique healthcare facility names after filtering: {total_filtered}\")\n",
    "    print(f\"Total person name entries removed: {total_removed}\")\n",
    "\n",
    "except overpy.exception.OverpassTooManyRequests:\n",
    "    print(\"Error: Too many requests. Please wait and try again later.\")\n",
    "except overpy.exception.OverpassGatewayTimeout:\n",
    "    print(\"Error: Gateway timeout. The server took too long to respond.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add wrongly classified strings back to the Hospital List based on keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a file\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        file_content = f.readlines()\n",
    "    return file_content\n",
    "\n",
    "# Function to append to a file (without overwriting)\n",
    "def append_to_file(file_path, content):\n",
    "    with open(file_path, 'a', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "        \n",
    "# Function to write a file (overwriting content)\n",
    "def write_to_file(file_path, content):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "        \n",
    "# helper function to extract the main name before '/'\n",
    "def get_main_name(facility):\n",
    "    \"\"\"\n",
    "    Extracts the main facility name before any '/' characters.\n",
    "\n",
    "    Parameters:\n",
    "    facility (str): The full facility string containing the name and additional info.\n",
    "\n",
    "    Returns:\n",
    "    str: The main facility name.\n",
    "    \"\"\"\n",
    "    return facility.split('/')[0].strip()\n",
    "\n",
    "# File paths\n",
    "person_names_removed_path = \"./data/OpenStreetMap_data/person_names_removed.txt\"\n",
    "filtered_healthcare_facilities_path = \"./data/OpenStreetMap_data/filtered_healthcare_facilities.txt\"\n",
    "\n",
    "# Load the list of person names\n",
    "person_names_removed = read_file(person_names_removed_path)\n",
    "\n",
    "# List of substrings to search for\n",
    "keywords = [\n",
    "    # Allgemeine Begriffe\n",
    "    \"arzt\", \"ärzt\", \"chirurg\", \"gemeinschaft\", \"klinik\", \"logie\", \"ologe\", \n",
    "    \"medizin\", \"praxis\", \"sanatorium\", \"therapie\", \"ambulanz\", \n",
    "\n",
    "    # Fachrichtungen und Behandlungen\n",
    "    \"anästhesie\", \"augen\", \"cardio\", \"dental\", \"derm\", \"endokrin\", \"gastro\", \"gyn\", \n",
    "    \"hämo\", \"hno\", \"kardio\", \"neuro\", \"onko\", \"optik\", \"ortho\", \"osteo\", \"pathie\", \n",
    "    \"pädie\", \"pneumo\", \"psych\", \"uro\", \"zahn\", \"zähne\", \"internist\",\n",
    "\n",
    "    # Verfahren und Diagnostik\n",
    "    \"blut\", \"ct\", \"diagnostik\", \"echo\", \"labor\", \"mrt\", \"radio\", \"rehabil\", \"spende\",\n",
    "\n",
    "    # Pflege und Behandlungsarten\n",
    "    \"betreuung\", \"ernährung\", \"geriatr\", \"hospiz\", \"intensiv\", \"palliativ\", \"pflege\", \n",
    "    \"physio\", \"rehaklinik\", \"therapeut\",\n",
    "\n",
    "    # Alternative Medizin\n",
    "    \"akupunkt\", \"heilpraktiker\", \"homöo\", \"naturheil\",\n",
    "\n",
    "    # Einrichtungen und Zentren\n",
    "    \"fach\", \"kranken\", \"notfall\", \"reha\", \"zentrum\", \"haus\", \"test\",\n",
    "\n",
    "    # Pädiatrie, Frauen und Spezialversorgung\n",
    "    \"diabetes\", \"frauen\", \"kinder\", \"lungen\",\n",
    "\n",
    "    # Zusätzliche Begriffe\n",
    "    \"apotheke\", \"arztpraxis\", \"behandl\", \"chirurgi\", \"gesundheitszentrum\", \n",
    "    \"klinisch\", \"untersuch\"\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize lists to store the matched and unmatched facilities\n",
    "matched_facilities = []\n",
    "unmatched_facilities = []\n",
    "\n",
    "# Loop through each healthcare facility name\n",
    "for facility in person_names_removed:\n",
    "    # Extract the main name before '/'\n",
    "    main_name = get_main_name(facility)\n",
    "    \n",
    "    # Check if any of the keywords are in the main name (case insensitive)\n",
    "    contains_keywords = any(keyword.lower() in main_name.lower() for keyword in keywords)\n",
    "\n",
    "    # Add facility to the matched list if it contains a keyword\n",
    "    if contains_keywords:\n",
    "        matched_facilities.append(facility)\n",
    "    else:\n",
    "        unmatched_facilities.append(facility)\n",
    "\n",
    "# Save the matched facilities to the filtered_healthcare_facilities.txt file\n",
    "append_to_file(filtered_healthcare_facilities_path, matched_facilities)\n",
    "\n",
    "# Save the remaining (unmatched) facilities back to the person_names_removed.txt file\n",
    "write_to_file(person_names_removed_path, unmatched_facilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Apoptheke from lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the input and output files\n",
    "person_names_removed_path = \"./data/OpenStreetMap_data/person_names_removed.txt\"\n",
    "filtered_healthcare_facilities_path = \"./data/OpenStreetMap_data/filtered_healthcare_facilities.txt\"\n",
    "apotheke_path = \"./data/OpenStreetMap_data/apotheke_entries.txt\"\n",
    "\n",
    "def remove_and_store_apotheke_entries(input_path, output_path):\n",
    "    # Read the input file\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Filter out lines that contain 'apotheke' and store them in a new list\n",
    "    apotheke_entries = [line for line in lines if 'apotheke' in line.lower()]\n",
    "    filtered_lines = [line for line in lines if 'apotheke' not in line.lower()]\n",
    "\n",
    "    # Write the filtered lines back to the original file\n",
    "    with open(input_path, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(filtered_lines)\n",
    "\n",
    "    # Append the 'apotheke' entries to the output file\n",
    "    if apotheke_entries:\n",
    "        with open(output_path, 'a', encoding='utf-8') as file:\n",
    "            file.writelines(apotheke_entries)\n",
    "\n",
    "# Run the function for both input files\n",
    "remove_and_store_apotheke_entries(person_names_removed_path, apotheke_path)\n",
    "remove_and_store_apotheke_entries(filtered_healthcare_facilities_path, apotheke_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Doctor Names from Hospital list with Regex Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# File paths\n",
    "filtered_healthcare_facilities_path = \"./data/OpenStreetMap_data/filtered_healthcare_facilities.txt\"\n",
    "person_names_removed_path = \"./data/OpenStreetMap_data/person_names_removed.txt\"\n",
    "\n",
    "# 1. Pattern to match one or more titles followed by optional punctuation and spaces\n",
    "title_pattern = r\"(?:(?:dr|phil|univ|medic|dres|med|dipl|psych|dent|vet)(?:\\.|\\b)\\s*)+\"\n",
    "\n",
    "# 2. Name pattern when a title is present: up to two words, allowing hyphens and apostrophes\n",
    "name_pattern_with_title = r\"([A-Z][\\w'-.]+(?:\\s[A-Z][\\w'-]+)?)\"\n",
    "\n",
    "# 3. Name pattern when no title is present: initial followed by a word\n",
    "name_pattern_without_title = r\"([A-Z]\\.\\s[A-Z][\\w'-]+)\\s*\"\n",
    "\n",
    "# 4. Full pattern for names with titles\n",
    "full_pattern_with_title = rf\"\"\"\n",
    "    ^                                   # Start of the string\n",
    "    (?P<title>{title_pattern})          # One or more titles (mandatory for the first name)\n",
    "    (?P<name>{name_pattern_with_title}) # First name following the title\n",
    "    (?:\\s*(?:&|/|und|\\+)\\s*             # Optional connector (&, /, und, or +) with spaces\n",
    "        (?:{title_pattern}\\s*)?         # Optional second title (may or may not be present)\n",
    "        {name_pattern_with_title}       # Second name (title is optional here)\n",
    "    )*                                  # Zero or more additional title-name pairs\n",
    "    \\s*$                                # End of the string, allowing for trailing whitespace\n",
    "\"\"\"\n",
    "\n",
    "# 5. Full pattern for names without titles\n",
    "full_pattern_without_title = rf\"^{name_pattern_without_title}$\"\n",
    "\n",
    "# 6. Compile the regex patterns with VERBOSE and IGNORECASE flags for readability and case-insensitivity\n",
    "compiled_pattern_with_title = re.compile(full_pattern_with_title, re.IGNORECASE | re.VERBOSE)\n",
    "compiled_pattern_without_title = re.compile(full_pattern_without_title, re.IGNORECASE)\n",
    "\n",
    "# Load the filtered healthcare facilities file\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "facilities = read_file(filtered_healthcare_facilities_path)\n",
    "\n",
    "# List to store recognized names\n",
    "recognized_names = []\n",
    "# List to store lines that don't match the regex (i.e., non-names)\n",
    "remaining_lines = []\n",
    "\n",
    "# Iterate over each line in the facilities file\n",
    "for line in facilities:\n",
    "    line = line.strip()  # Strip leading/trailing whitespaces and newline characters\n",
    "    line_name = get_main_name(line)\n",
    "    match = compiled_pattern_with_title.fullmatch(line_name)\n",
    "    if match:\n",
    "        # If a match is found, append the name (with or without title) to the recognized names\n",
    "        recognized_names.append(line + '\\n')  # Ensure newline\n",
    "    else:\n",
    "        match = compiled_pattern_without_title.fullmatch(line_name)\n",
    "        if match:\n",
    "            recognized_names.append(line + '\\n')  # Ensure newline\n",
    "        else:\n",
    "            # If no match, retain the line in the remaining_lines\n",
    "            remaining_lines.append(line + '\\n')  # Ensure newline\n",
    "\n",
    "# Function to append to a file (without overwriting)\n",
    "def append_to_file(file_path, content):\n",
    "    with open(file_path, 'a', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "\n",
    "# Function to write a file (overwriting content)\n",
    "def write_to_file(file_path, content):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "\n",
    "# Append the recognized names to the person_names_removed.txt file\n",
    "append_to_file(person_names_removed_path, recognized_names)\n",
    "\n",
    "# Write the remaining lines back to the filtered_healthcare_facilities.txt file\n",
    "write_to_file(filtered_healthcare_facilities_path, remaining_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine two Hospital Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined list saved to /home/mseiferling/vector_search/data/OpenStreetMap_data/Combined_healthcare_facilities.txt\n"
     ]
    }
   ],
   "source": [
    "# Define the file paths\n",
    "healthcare_path = \"/home/mseiferling/vector_search/data/OpenStreetMap_data/filtered_healthcare_facilities.txt\"\n",
    "krankenhaus_path = \"/home/mseiferling/vector_search/data/Krankenhaus.txt\"\n",
    "output_file = \"/home/mseiferling/vector_search/data/OpenStreetMap_data/Combined_healthcare_facilities.txt\"\n",
    "\n",
    "# Initialize a dictionary to map main names to full entries\n",
    "combined_hospitals = {}\n",
    "\n",
    "# Read the contents of the first file and populate the dictionary\n",
    "with open(healthcare_path, 'r', encoding='utf-8') as file1:\n",
    "    for line in file1:\n",
    "        full_name = line.strip()\n",
    "        if not full_name:\n",
    "            continue  # Skip empty lines\n",
    "        main_name = get_main_name(full_name)\n",
    "        combined_hospitals[main_name.lower()] = full_name  # Use lowercase for case-insensitive matching\n",
    "\n",
    "# Read the contents of the second file and add new unique entries to the dictionary\n",
    "with open(krankenhaus_path, 'r', encoding='utf-8') as file2:\n",
    "    for line in file2:\n",
    "        full_name = line.strip()\n",
    "        if not full_name:\n",
    "            continue  # Skip empty lines\n",
    "        main_name = get_main_name(full_name)\n",
    "        main_name_lower = main_name.lower()\n",
    "        if main_name_lower not in combined_hospitals:\n",
    "            combined_hospitals[main_name_lower] = full_name\n",
    "\n",
    "# Prepare the combined list of full names\n",
    "updated_hospitals = sorted(combined_hospitals.values())\n",
    "\n",
    "# Save the combined list to the output file\n",
    "with open(output_file, 'w', encoding='utf-8') as output:\n",
    "    for hospital in updated_hospitals:\n",
    "        output.write(hospital + '\\n')\n",
    "\n",
    "print(f\"Combined list saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output file paths\n",
    "input_file = \"/home/mseiferling/vector_search/data/OpenStreetMap_data/Combined_healthcare_facilities.txt\"\n",
    "output_file = \"/home/mseiferling/vector_search/data/OpenStreetMap_data/new_Combined_healthcare_facilities.txt\"\n",
    "\n",
    "# Open the input file, clean the lines, and write to the output file\n",
    "with open(input_file, 'r', encoding='utf-8', errors='replace') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    for line in infile:\n",
    "        # Replace unusual line terminators (PS, LS) with standard newlines\n",
    "        cleaned_line = line.replace('\\u2028', '\\n').replace('\\u2029', '\\n').strip()  # LS = \\u2028, PS = \\u2029\n",
    "        outfile.write(cleaned_line + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allgemeinarztpraxis Dr. Killer -> MISC\n",
      "Token: Allgemeinarztpraxis, POS: NOUN\n",
      "Token: Dr., POS: NOUN\n",
      "Token: Killer, POS: NOUN\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the SpaCy German model for NER\n",
    "nlp = spacy.load(\"de_core_news_lg\") # python -m spacy download de_dep_news_trf\n",
    "\n",
    "\n",
    "# Example text\n",
    "text = \"Allgemeinarztpraxis Dr. Killer\"\n",
    "\n",
    "# Process the text with the NER model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the recognized entities and their labels\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} -> {ent.label_}\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}, POS: {token.pos_}\") # POS: NOUN(Common Noun) POS: PROPN (specific Names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
