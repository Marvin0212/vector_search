{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "Total healthcare facility names retrieved: 62584\n",
      "Total unique healthcare facility names after filtering: 22647\n",
      "Total person name entries removed: 39937\n"
     ]
    }
   ],
   "source": [
    "import overpy\n",
    "import spacy\n",
    "\n",
    "# Initialize the Overpass API\n",
    "api = overpy.Overpass() # Read Only connection to OpenStreetMap\n",
    "\n",
    "# Load the SpaCy German model for NER\n",
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "\n",
    "# Overpass QL query to get all relevant healthcare facilities in Germany\n",
    "overpass_query = \"\"\"\n",
    "[out:json][timeout:180];\n",
    "area[\"ISO3166-1\"=\"DE\"][admin_level=2];\n",
    "(\n",
    "  // Healthcare facilities\n",
    "  node[\"healthcare\"](area);\n",
    "  way[\"healthcare\"](area);\n",
    "  relation[\"healthcare\"](area);\n",
    ");\n",
    "out body;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Execute the Overpass query\n",
    "    result = api.query(overpass_query)\n",
    "\n",
    "    # Initialize sets to store unique names\n",
    "    all_facility_names = set()\n",
    "    filtered_facility_names = set()\n",
    "    person_names_removed = set()\n",
    "\n",
    "    # Function to extract and add names to the set\n",
    "    def extract_name(element):\n",
    "        name = element.tags.get(\"name\")\n",
    "        if name:\n",
    "            name = name.strip()\n",
    "            if name and name.lower() != \"no name\":\n",
    "                all_facility_names.add(name)\n",
    "\n",
    "    # Process nodes\n",
    "    for node in result.nodes:\n",
    "        extract_name(node)\n",
    "\n",
    "    # Process ways\n",
    "    for way in result.ways:\n",
    "        extract_name(way)\n",
    "\n",
    "    # Process relations\n",
    "    for relation in result.relations:\n",
    "        extract_name(relation)\n",
    "\n",
    "\n",
    "    # Save all facility names to a text file\n",
    "    all_output_file = './data/OpenStreetMap_data/all_healthcare_facilities.txt'\n",
    "    with open(all_output_file, 'w', encoding='utf-8') as f:\n",
    "        for name in sorted(all_facility_names):\n",
    "            f.write(name + '\\n')\n",
    "\n",
    "    # Function to filter out person names\n",
    "    def filter_person_names(name):\n",
    "        doc = nlp(name)\n",
    "        # Check if any entity in the name is labeled as PERSON with Spacy\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PER\":\n",
    "                return False  # It's a person name\n",
    "        return True  # It's a facility name\n",
    "\n",
    "    # Apply the filter to all facility names\n",
    "    for name in all_facility_names:\n",
    "        if filter_person_names(name):\n",
    "            filtered_facility_names.add(name)\n",
    "        else:\n",
    "            person_names_removed.add(name)\n",
    "\n",
    "\n",
    "    # Save the filtered facility names to a text file\n",
    "    filtered_output_file = './data/OpenStreetMap_data/filtered_healthcare_facilities.txt'\n",
    "    with open(filtered_output_file, 'w', encoding='utf-8') as f:\n",
    "        for name in sorted(filtered_facility_names):\n",
    "            f.write(name + '\\n')\n",
    "\n",
    "    # Save the person names that were removed to a separate text file\n",
    "    person_removed_file = './data/OpenStreetMap_data/person_names_removed.txt'\n",
    "    with open(person_removed_file, 'w', encoding='utf-8') as f:\n",
    "        for name in sorted(person_names_removed):\n",
    "            f.write(name + '\\n')\n",
    "\n",
    "    # Compare the two lists and report counts\n",
    "    total_all = len(all_facility_names)\n",
    "    total_filtered = len(filtered_facility_names)\n",
    "    total_removed = len(person_names_removed)\n",
    "\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(f\"Total healthcare facility names retrieved: {total_all}\")\n",
    "    print(f\"Total unique healthcare facility names after filtering: {total_filtered}\")\n",
    "    print(f\"Total person name entries removed: {total_removed}\")\n",
    "\n",
    "except overpy.exception.OverpassTooManyRequests:\n",
    "    print(\"Error: Too many requests. Please wait and try again later.\")\n",
    "except overpy.exception.OverpassGatewayTimeout:\n",
    "    print(\"Error: Gateway timeout. The server took too long to respond.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add wrongly classified strings back to the Hospital List based on keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a file\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        file_content = f.readlines()\n",
    "    return file_content\n",
    "\n",
    "# Function to append to a file (without overwriting)\n",
    "def append_to_file(file_path, content):\n",
    "    with open(file_path, 'a', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "        \n",
    "# Function to write a file (overwriting content)\n",
    "def write_to_file(file_path, content):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "\n",
    "# File paths\n",
    "person_names_removed_path = \"./data/OpenStreetMap_data/person_names_removed.txt\"\n",
    "filtered_healthcare_facilities_path = \"./data/OpenStreetMap_data/filtered_healthcare_facilities.txt\"\n",
    "\n",
    "# Load the list of person names\n",
    "person_names_removed = read_file(person_names_removed_path)\n",
    "\n",
    "# List of substrings to search for\n",
    "keywords = [\n",
    "    # General terms\n",
    "    \"klinik\", \"praxis\", \"arzt\", \"ärzt\", \"therapie\", \"haus\", \"medizin\", \"zentrum\", \n",
    "    \"chirurg\", \"pflege\", \"ambulanz\", \"sanatorium\", \"ologe\", \"gemeinschaft\",\"logie\",\"psychiatrie\",\n",
    "\n",
    "    # Specialties and treatments\n",
    "    \"herz\", \"uro\", \"neuro\", \"kardio\", \"onko\", \"gyn\", \"pneumo\", \n",
    "    \"derm\", \"endokrin\", \"psycho\", \"anästhesie\", \"zahn\", \"zähne\", \"optik\", \"hno\", \n",
    "    \"ortho\", \"osteo\", \"pathie\", \"augen\", \"uro\", \"hämo\", \"dental\",\"gastro\",\"pädie\",\n",
    "\n",
    "    # Common procedures and diagnostic terms\n",
    "    \"labor\", \"mrt\", \"ct\", \"diagnostik\", \"radio\", \"rehabil\", \"blut\", \n",
    "    \"spende\",\"echo\", \n",
    "\n",
    "    # Types of care and treatment\n",
    "    \"physio\", \"palliativ\", \"intensiv\", \"pflege\", \"betreuung\", \"hospiz\", \n",
    "    \"geriatr\", \"rehaklinik\", \"ernährung\",\"therapeut\"\n",
    "\n",
    "    # Alternative medicine\n",
    "    \"heil\", \"natur\", \"homöo\", \"akupunkt\",\n",
    "\n",
    "    # Facilities and centers\n",
    "    \"logo\", \"fach\", \"zentrum\", \"kranken\", \"notfall\", \"prax\", \"chir\", \"reha\",\n",
    "\n",
    "    # Pediatric, women's and specialty care\n",
    "    \"kinder\", \"frauen\", \"diabetes\", \"lungen\"\n",
    "]\n",
    "\n",
    "# Initialize lists to store the matched and unmatched facilities\n",
    "matched_facilities = []\n",
    "unmatched_facilities = []\n",
    "\n",
    "# Loop through each healthcare facility name\n",
    "for facility in person_names_removed:\n",
    "    # Check if any of the keywords are in the facility name (case insensitive)\n",
    "    contains_keywords = any(keyword.lower() in facility.lower() for keyword in keywords)\n",
    "\n",
    "    # Add facility to the matched list if it contains a keyword or \"med\"/\"dent\" but not \"med.\"/\"dent.\"\n",
    "    if contains_keywords:\n",
    "        matched_facilities.append(facility)\n",
    "    else:\n",
    "        unmatched_facilities.append(facility)\n",
    "\n",
    "# Save the matched facilities to the filtered_healthcare_facilities.txt file\n",
    "append_to_file(filtered_healthcare_facilities_path, matched_facilities)\n",
    "\n",
    "# Save the remaining (unmatched) facilities back to the person_names_removed.txt file\n",
    "write_to_file(person_names_removed_path, unmatched_facilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Apoptheke from lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the input and output files\n",
    "person_names_removed_path = \"./data/OpenStreetMap_data/person_names_removed.txt\"\n",
    "filtered_healthcare_facilities_path = \"./data/OpenStreetMap_data/filtered_healthcare_facilities.txt\"\n",
    "apotheke_path = \"./data/OpenStreetMap_data/apotheke_entries.txt\"\n",
    "\n",
    "def remove_and_store_apotheke_entries(input_path, output_path):\n",
    "    # Read the input file\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Filter out lines that contain 'apotheke' and store them in a new list\n",
    "    apotheke_entries = [line for line in lines if 'apotheke' in line.lower()]\n",
    "    filtered_lines = [line for line in lines if 'apotheke' not in line.lower()]\n",
    "\n",
    "    # Write the filtered lines back to the original file\n",
    "    with open(input_path, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(filtered_lines)\n",
    "\n",
    "    # Append the 'apotheke' entries to the output file\n",
    "    if apotheke_entries:\n",
    "        with open(output_path, 'a', encoding='utf-8') as file:\n",
    "            file.writelines(apotheke_entries)\n",
    "\n",
    "# Run the function for both input files\n",
    "remove_and_store_apotheke_entries(person_names_removed_path, apotheke_path)\n",
    "remove_and_store_apotheke_entries(filtered_healthcare_facilities_path, apotheke_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Doctor Names from Hospital list with Regex Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# File paths\n",
    "filtered_healthcare_facilities_path = \"./data/OpenStreetMap_data/filtered_healthcare_facilities.txt\"\n",
    "person_names_removed_path = \"./data/OpenStreetMap_data/person_names_removed.txt\"\n",
    "\n",
    "# 1. Pattern to match one or more titles followed by optional punctuation and spaces\n",
    "title_pattern = r\"(?:(?:dr|phil|univ|medic|dres|med|dipl|psych|dent|vet)(?:\\.|\\b)\\s*)+\"\n",
    "\n",
    "# 2. Name pattern when a title is present: up to two words, allowing hyphens and apostrophes\n",
    "name_pattern_with_title = r\"([A-Z][\\w'-.]+(?:\\s[A-Z][\\w'-]+)?)\"\n",
    "\n",
    "# 3. Name pattern when no title is present: initial followed by a word\n",
    "name_pattern_without_title = r\"([A-Z]\\.\\s[A-Z][\\w'-]+)\\s*\"\n",
    "\n",
    "# 4. Full pattern for names with titles\n",
    "full_pattern_with_title = rf\"\"\"\n",
    "    ^                                   # Start of the string\n",
    "    (?P<title>{title_pattern})          # One or more titles (mandatory for the first name)\n",
    "    (?P<name>{name_pattern_with_title}) # First name following the title\n",
    "    (?:\\s*(?:&|/|und|\\+)\\s*             # Optional connector (&, /, und, or +) with spaces\n",
    "        (?:{title_pattern}\\s*)?         # Optional second title (may or may not be present)\n",
    "        {name_pattern_with_title}       # Second name (title is optional here)\n",
    "    )*                                  # Zero or more additional title-name pairs\n",
    "    \\s*$                                # End of the string, allowing for trailing whitespace\n",
    "\"\"\"\n",
    "\n",
    "# 5. Full pattern for names without titles\n",
    "full_pattern_without_title = rf\"^{name_pattern_without_title}$\"\n",
    "\n",
    "# 6. Compile the regex patterns with VERBOSE and IGNORECASE flags for readability and case-insensitivity\n",
    "compiled_pattern_with_title = re.compile(full_pattern_with_title, re.IGNORECASE | re.VERBOSE)\n",
    "compiled_pattern_without_title = re.compile(full_pattern_without_title, re.IGNORECASE)\n",
    "\n",
    "# Load the filtered healthcare facilities file\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "facilities = read_file(filtered_healthcare_facilities_path)\n",
    "\n",
    "# List to store recognized names\n",
    "recognized_names = []\n",
    "# List to store lines that don't match the regex (i.e., non-names)\n",
    "remaining_lines = []\n",
    "\n",
    "# Iterate over each line in the facilities file\n",
    "for line in facilities:\n",
    "    line = line.strip()  # Strip leading/trailing whitespaces and newline characters\n",
    "    match = compiled_pattern_with_title.fullmatch(line)\n",
    "    if match:\n",
    "        # If a match is found, append the name (with or without title) to the recognized names\n",
    "        recognized_names.append(match.group() + '\\n')  # Ensure newline\n",
    "    else:\n",
    "        match = compiled_pattern_without_title.fullmatch(line)\n",
    "        if match:\n",
    "            recognized_names.append(match.group() + '\\n')  # Ensure newline\n",
    "        else:\n",
    "            # If no match, retain the line in the remaining_lines\n",
    "            remaining_lines.append(line + '\\n')  # Ensure newline\n",
    "\n",
    "# Function to append to a file (without overwriting)\n",
    "def append_to_file(file_path, content):\n",
    "    with open(file_path, 'a', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "\n",
    "# Function to write a file (overwriting content)\n",
    "def write_to_file(file_path, content):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "\n",
    "# Append the recognized names to the person_names_removed.txt file\n",
    "append_to_file(person_names_removed_path, recognized_names)\n",
    "\n",
    "# Write the remaining lines back to the filtered_healthcare_facilities.txt file\n",
    "write_to_file(filtered_healthcare_facilities_path, remaining_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine two Hospital Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "healthcare_path = \"/home/mseiferling/vector_search/data/OpenStreetMap_data/filtered_healthcare_facilities.txt\"\n",
    "krankenhaus_path = \"/home/mseiferling/vector_search/data/Krankenhaus.txt\"\n",
    "output_file = \"/home/mseiferling/vector_search/data/OpenStreetMap_data/Combined_healthcare_facilities.txt\"\n",
    "\n",
    "# Read the contents of the first file\n",
    "with open(healthcare_path, 'r') as file1:\n",
    "    hospitals_in_file1 = set(line.strip() for line in file1)\n",
    "\n",
    "# Read the contents of the second file\n",
    "with open(krankenhaus_path, 'r') as file2:\n",
    "    hospitals_in_file2 = set(line.strip() for line in file2)\n",
    "\n",
    "# Find hospitals that are in the second file but not in the first file\n",
    "new_hospitals = hospitals_in_file2 - hospitals_in_file1\n",
    "\n",
    "# Combine the contents of the first file with the new hospitals\n",
    "updated_hospitals = hospitals_in_file1.union(new_hospitals)\n",
    "\n",
    "# save the updated list\n",
    "with open(output_file, 'w') as output:\n",
    "    for hospital in sorted(updated_hospitals):  # Sort the list for consistency\n",
    "        output.write(hospital + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output file paths\n",
    "input_file = \"/home/mseiferling/vector_search/data/OpenStreetMap_data/Combined_healthcare_facilities.txt\"\n",
    "output_file = \"/home/mseiferling/vector_search/data/OpenStreetMap_data/new_Combined_healthcare_facilities.txt\"\n",
    "\n",
    "# Open the input file, clean the lines, and write to the output file\n",
    "with open(input_file, 'r', encoding='utf-8', errors='replace') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    for line in infile:\n",
    "        # Replace unusual line terminators (PS, LS) with standard newlines\n",
    "        cleaned_line = line.replace('\\u2028', '\\n').replace('\\u2029', '\\n').strip()  # LS = \\u2028, PS = \\u2029\n",
    "        outfile.write(cleaned_line + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARSTENS -> ORG\n",
      "Token: PETER, POS: PROPN\n",
      "Token: CARSTENS, POS: PROPN\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the SpaCy German model for NER\n",
    "nlp = spacy.load(\"de_core_news_lg\") # python -m spacy download de_dep_news_trf\n",
    "\n",
    "\n",
    "# Example text\n",
    "text = \"PETER CARSTENS\"\n",
    "\n",
    "# Process the text with the NER model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the recognized entities and their labels\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} -> {ent.label_}\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}, POS: {token.pos_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
