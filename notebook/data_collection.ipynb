{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "Total healthcare facility names retrieved: 62584\n",
      "Total unique healthcare facility names after filtering: 22647\n",
      "Total person name entries removed: 39937\n"
     ]
    }
   ],
   "source": [
    "import overpy\n",
    "import spacy\n",
    "\n",
    "# Initialize the Overpass API\n",
    "api = overpy.Overpass() # Read Only connection to OpenStreetMap\n",
    "\n",
    "# Load the SpaCy German model for NER\n",
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "\n",
    "# Overpass QL query to get all relevant healthcare facilities in Germany\n",
    "overpass_query = \"\"\"\n",
    "[out:json][timeout:180];\n",
    "area[\"ISO3166-1\"=\"DE\"][admin_level=2];\n",
    "(\n",
    "  // Healthcare facilities\n",
    "  node[\"healthcare\"](area);\n",
    "  way[\"healthcare\"](area);\n",
    "  relation[\"healthcare\"](area);\n",
    ");\n",
    "out body;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Execute the Overpass query\n",
    "    result = api.query(overpass_query)\n",
    "\n",
    "    # Initialize sets to store unique names\n",
    "    all_facility_names = set()\n",
    "    filtered_facility_names = set()\n",
    "    person_names_removed = set()\n",
    "\n",
    "    # Function to extract and add names to the set\n",
    "    def extract_name(element):\n",
    "        name = element.tags.get(\"name\")\n",
    "        if name:\n",
    "            name = name.strip()\n",
    "            if name and name.lower() != \"no name\":\n",
    "                all_facility_names.add(name)\n",
    "\n",
    "    # Process nodes\n",
    "    for node in result.nodes:\n",
    "        extract_name(node)\n",
    "\n",
    "    # Process ways\n",
    "    for way in result.ways:\n",
    "        extract_name(way)\n",
    "\n",
    "    # Process relations\n",
    "    for relation in result.relations:\n",
    "        extract_name(relation)\n",
    "\n",
    "\n",
    "    # Save all facility names to a text file\n",
    "    all_output_file = './data/OpenStreetMap_data/all_healthcare_facilities.txt'\n",
    "    with open(all_output_file, 'w', encoding='utf-8') as f:\n",
    "        for name in sorted(all_facility_names):\n",
    "            f.write(name + '\\n')\n",
    "\n",
    "    # Function to filter out person names\n",
    "    def filter_person_names(name):\n",
    "        doc = nlp(name)\n",
    "        # Check if any entity in the name is labeled as PERSON with Spacy\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PER\":\n",
    "                return False  # It's a person name\n",
    "        return True  # It's a facility name\n",
    "\n",
    "    # Apply the filter to all facility names\n",
    "    for name in all_facility_names:\n",
    "        if filter_person_names(name):\n",
    "            filtered_facility_names.add(name)\n",
    "        else:\n",
    "            person_names_removed.add(name)\n",
    "\n",
    "\n",
    "    # Save the filtered facility names to a text file\n",
    "    filtered_output_file = './data/OpenStreetMap_data/filtered_healthcare_facilities.txt'\n",
    "    with open(filtered_output_file, 'w', encoding='utf-8') as f:\n",
    "        for name in sorted(filtered_facility_names):\n",
    "            f.write(name + '\\n')\n",
    "\n",
    "    # Save the person names that were removed to a separate text file\n",
    "    person_removed_file = './data/OpenStreetMap_data/person_names_removed.txt'\n",
    "    with open(person_removed_file, 'w', encoding='utf-8') as f:\n",
    "        for name in sorted(person_names_removed):\n",
    "            f.write(name + '\\n')\n",
    "\n",
    "    # Compare the two lists and report counts\n",
    "    total_all = len(all_facility_names)\n",
    "    total_filtered = len(filtered_facility_names)\n",
    "    total_removed = len(person_names_removed)\n",
    "\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(f\"Total healthcare facility names retrieved: {total_all}\")\n",
    "    print(f\"Total unique healthcare facility names after filtering: {total_filtered}\")\n",
    "    print(f\"Total person name entries removed: {total_removed}\")\n",
    "\n",
    "except overpy.exception.OverpassTooManyRequests:\n",
    "    print(\"Error: Too many requests. Please wait and try again later.\")\n",
    "except overpy.exception.OverpassGatewayTimeout:\n",
    "    print(\"Error: Gateway timeout. The server took too long to respond.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add wrongly classified strings back to the Hospital List based on keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a file\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        file_content = f.readlines()\n",
    "    return file_content\n",
    "\n",
    "# Function to append to a file (without overwriting)\n",
    "def append_to_file(file_path, content):\n",
    "    with open(file_path, 'a', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "        \n",
    "# Function to write a file (overwriting content)\n",
    "def write_to_file(file_path, content):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "\n",
    "# File paths\n",
    "person_names_removed_path = \"./data/OpenStreetMap_data/person_names_removed.txt\"\n",
    "filtered_healthcare_facilities_path = \"./data/OpenStreetMap_data/filtered_healthcare_facilities.txt\"\n",
    "\n",
    "# Load the list of person names\n",
    "person_names_removed = read_file(person_names_removed_path)\n",
    "\n",
    "# List of substrings to search for\n",
    "keywords = [\n",
    "    # Allgemeine Begriffe\n",
    "    \"arzt\", \"ärzt\", \"chirurg\", \"gemeinschaft\", \"klinik\", \"logie\", \"ologe\", \n",
    "    \"medizin\", \"praxis\", \"sanatorium\", \"therapie\", \"ambulanz\", \n",
    "\n",
    "    # Fachrichtungen und Behandlungen\n",
    "    \"anästhesie\", \"augen\", \"cardio\", \"dental\", \"derm\", \"endokrin\", \"gastro\", \"gyn\", \n",
    "    \"hämo\", \"hno\", \"kardio\", \"neuro\", \"onko\", \"optik\", \"ortho\", \"osteo\", \"pathie\", \n",
    "    \"pädie\", \"pneumo\", \"psych\", \"uro\", \"zahn\", \"zähne\",\n",
    "\n",
    "    # Verfahren und Diagnostik\n",
    "    \"blut\", \"ct\", \"diagnostik\", \"echo\", \"labor\", \"mrt\", \"radio\", \"rehabil\", \"spende\",\n",
    "\n",
    "    # Pflege und Behandlungsarten\n",
    "    \"betreuung\", \"ernährung\", \"geriatr\", \"hospiz\", \"intensiv\", \"palliativ\", \"pflege\", \n",
    "    \"physio\", \"rehaklinik\", \"therapeut\",\n",
    "\n",
    "    # Alternative Medizin\n",
    "    \"akupunkt\", \"heilpraktiker\", \"homöo\", \"naturheil\",\n",
    "\n",
    "    # Einrichtungen und Zentren\n",
    "    \"fach\", \"kranken\", \"notfall\", \"reha\", \"zentrum\", \"haus\", \"test\",\n",
    "\n",
    "    # Pädiatrie, Frauen und Spezialversorgung\n",
    "    \"diabetes\", \"frauen\", \"kinder\", \"lungen\",\n",
    "\n",
    "    # Zusätzliche Begriffe\n",
    "    \"apotheke\", \"arztpraxis\", \"behandl\", \"chirurgi\", \"gesundheitszentrum\", \n",
    "    \"klinisch\", \"untersuch\"\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize lists to store the matched and unmatched facilities\n",
    "matched_facilities = []\n",
    "unmatched_facilities = []\n",
    "\n",
    "# Loop through each healthcare facility name\n",
    "for facility in person_names_removed:\n",
    "    # Check if any of the keywords are in the facility name (case insensitive)\n",
    "    contains_keywords = any(keyword.lower() in facility.lower() for keyword in keywords)\n",
    "\n",
    "    # Add facility to the matched list if it contains a keyword or \"med\"/\"dent\" but not \"med.\"/\"dent.\"\n",
    "    if contains_keywords:\n",
    "        matched_facilities.append(facility)\n",
    "    else:\n",
    "        unmatched_facilities.append(facility)\n",
    "\n",
    "# Save the matched facilities to the filtered_healthcare_facilities.txt file\n",
    "append_to_file(filtered_healthcare_facilities_path, matched_facilities)\n",
    "\n",
    "# Save the remaining (unmatched) facilities back to the person_names_removed.txt file\n",
    "write_to_file(person_names_removed_path, unmatched_facilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Apoptheke from lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the input and output files\n",
    "person_names_removed_path = \"./data/OpenStreetMap_data/person_names_removed.txt\"\n",
    "filtered_healthcare_facilities_path = \"./data/OpenStreetMap_data/filtered_healthcare_facilities.txt\"\n",
    "apotheke_path = \"./data/OpenStreetMap_data/apotheke_entries.txt\"\n",
    "\n",
    "def remove_and_store_apotheke_entries(input_path, output_path):\n",
    "    # Read the input file\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Filter out lines that contain 'apotheke' and store them in a new list\n",
    "    apotheke_entries = [line for line in lines if 'apotheke' in line.lower()]\n",
    "    filtered_lines = [line for line in lines if 'apotheke' not in line.lower()]\n",
    "\n",
    "    # Write the filtered lines back to the original file\n",
    "    with open(input_path, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(filtered_lines)\n",
    "\n",
    "    # Append the 'apotheke' entries to the output file\n",
    "    if apotheke_entries:\n",
    "        with open(output_path, 'a', encoding='utf-8') as file:\n",
    "            file.writelines(apotheke_entries)\n",
    "\n",
    "# Run the function for both input files\n",
    "remove_and_store_apotheke_entries(person_names_removed_path, apotheke_path)\n",
    "remove_and_store_apotheke_entries(filtered_healthcare_facilities_path, apotheke_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Doctor Names from Hospital list with Regex Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# File paths\n",
    "filtered_healthcare_facilities_path = \"./data/OpenStreetMap_data/filtered_healthcare_facilities.txt\"\n",
    "person_names_removed_path = \"./data/OpenStreetMap_data/person_names_removed.txt\"\n",
    "\n",
    "# 1. Pattern to match one or more titles followed by optional punctuation and spaces\n",
    "title_pattern = r\"(?:(?:dr|phil|univ|medic|dres|med|dipl|psych|dent|vet)(?:\\.|\\b)\\s*)+\"\n",
    "\n",
    "# 2. Name pattern when a title is present: up to two words, allowing hyphens and apostrophes\n",
    "name_pattern_with_title = r\"([A-Z][\\w'-.]+(?:\\s[A-Z][\\w'-]+)?)\"\n",
    "\n",
    "# 3. Name pattern when no title is present: initial followed by a word\n",
    "name_pattern_without_title = r\"([A-Z]\\.\\s[A-Z][\\w'-]+)\\s*\"\n",
    "\n",
    "# 4. Full pattern for names with titles\n",
    "full_pattern_with_title = rf\"\"\"\n",
    "    ^                                   # Start of the string\n",
    "    (?P<title>{title_pattern})          # One or more titles (mandatory for the first name)\n",
    "    (?P<name>{name_pattern_with_title}) # First name following the title\n",
    "    (?:\\s*(?:&|/|und|\\+)\\s*             # Optional connector (&, /, und, or +) with spaces\n",
    "        (?:{title_pattern}\\s*)?         # Optional second title (may or may not be present)\n",
    "        {name_pattern_with_title}       # Second name (title is optional here)\n",
    "    )*                                  # Zero or more additional title-name pairs\n",
    "    \\s*$                                # End of the string, allowing for trailing whitespace\n",
    "\"\"\"\n",
    "\n",
    "# 5. Full pattern for names without titles\n",
    "full_pattern_without_title = rf\"^{name_pattern_without_title}$\"\n",
    "\n",
    "# 6. Compile the regex patterns with VERBOSE and IGNORECASE flags for readability and case-insensitivity\n",
    "compiled_pattern_with_title = re.compile(full_pattern_with_title, re.IGNORECASE | re.VERBOSE)\n",
    "compiled_pattern_without_title = re.compile(full_pattern_without_title, re.IGNORECASE)\n",
    "\n",
    "# Load the filtered healthcare facilities file\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "facilities = read_file(filtered_healthcare_facilities_path)\n",
    "\n",
    "# List to store recognized names\n",
    "recognized_names = []\n",
    "# List to store lines that don't match the regex (i.e., non-names)\n",
    "remaining_lines = []\n",
    "\n",
    "# Iterate over each line in the facilities file\n",
    "for line in facilities:\n",
    "    line = line.strip()  # Strip leading/trailing whitespaces and newline characters\n",
    "    match = compiled_pattern_with_title.fullmatch(line)\n",
    "    if match:\n",
    "        # If a match is found, append the name (with or without title) to the recognized names\n",
    "        recognized_names.append(match.group() + '\\n')  # Ensure newline\n",
    "    else:\n",
    "        match = compiled_pattern_without_title.fullmatch(line)\n",
    "        if match:\n",
    "            recognized_names.append(match.group() + '\\n')  # Ensure newline\n",
    "        else:\n",
    "            # If no match, retain the line in the remaining_lines\n",
    "            remaining_lines.append(line + '\\n')  # Ensure newline\n",
    "\n",
    "# Function to append to a file (without overwriting)\n",
    "def append_to_file(file_path, content):\n",
    "    with open(file_path, 'a', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "\n",
    "# Function to write a file (overwriting content)\n",
    "def write_to_file(file_path, content):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(content)\n",
    "\n",
    "# Append the recognized names to the person_names_removed.txt file\n",
    "append_to_file(person_names_removed_path, recognized_names)\n",
    "\n",
    "# Write the remaining lines back to the filtered_healthcare_facilities.txt file\n",
    "write_to_file(filtered_healthcare_facilities_path, remaining_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine two Hospital Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "healthcare_path = \"/home/mseiferling/vector_search/data/OpenStreetMap_data/filtered_healthcare_facilities.txt\"\n",
    "krankenhaus_path = \"/home/mseiferling/vector_search/data/Krankenhaus.txt\"\n",
    "output_file = \"/home/mseiferling/vector_search/data/OpenStreetMap_data/Combined_healthcare_facilities.txt\"\n",
    "\n",
    "# Read the contents of the first file\n",
    "with open(healthcare_path, 'r') as file1:\n",
    "    hospitals_in_file1 = set(line.strip() for line in file1)\n",
    "\n",
    "# Read the contents of the second file\n",
    "with open(krankenhaus_path, 'r') as file2:\n",
    "    hospitals_in_file2 = set(line.strip() for line in file2)\n",
    "\n",
    "# Find hospitals that are in the second file but not in the first file\n",
    "new_hospitals = hospitals_in_file2 - hospitals_in_file1\n",
    "\n",
    "# Combine the contents of the first file with the new hospitals\n",
    "updated_hospitals = hospitals_in_file1.union(new_hospitals)\n",
    "\n",
    "# save the updated list\n",
    "with open(output_file, 'w') as output:\n",
    "    for hospital in sorted(updated_hospitals):  # Sort the list for consistency\n",
    "        output.write(hospital + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output file paths\n",
    "input_file = \"/home/mseiferling/vector_search/data/OpenStreetMap_data/Combined_healthcare_facilities.txt\"\n",
    "output_file = \"/home/mseiferling/vector_search/data/OpenStreetMap_data/new_Combined_healthcare_facilities.txt\"\n",
    "\n",
    "# Open the input file, clean the lines, and write to the output file\n",
    "with open(input_file, 'r', encoding='utf-8', errors='replace') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    for line in infile:\n",
    "        # Replace unusual line terminators (PS, LS) with standard newlines\n",
    "        cleaned_line = line.replace('\\u2028', '\\n').replace('\\u2029', '\\n').strip()  # LS = \\u2028, PS = \\u2029\n",
    "        outfile.write(cleaned_line + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allgemeinarztpraxis Dr. Killer -> MISC\n",
      "Token: Allgemeinarztpraxis, POS: NOUN\n",
      "Token: Dr., POS: NOUN\n",
      "Token: Killer, POS: NOUN\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the SpaCy German model for NER\n",
    "nlp = spacy.load(\"de_core_news_lg\") # python -m spacy download de_dep_news_trf\n",
    "\n",
    "\n",
    "# Example text\n",
    "text = \"Allgemeinarztpraxis Dr. Killer\"\n",
    "\n",
    "# Process the text with the NER model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the recognized entities and their labels\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} -> {ent.label_}\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}, POS: {token.pos_}\") # POS: NOUN(Common Noun) POS: PROPN (specific Names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
