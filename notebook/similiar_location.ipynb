{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mseiferling/.venvs/vector/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# Load hospital Names from a Text File\n",
    "def load_hospital_names(text_file):\n",
    "    with open(text_file, 'r', encoding='utf-8') as f:\n",
    "        hospital_names = [line.strip() for line in f if line.strip()]\n",
    "    return hospital_names\n",
    "\n",
    "# Compute Embeddings\n",
    "def compute_embeddings(model, sentences, batch_size=512):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Computing Embeddings\"):\n",
    "        batch = sentences[i:i+batch_size] # remove alpha numeric?\n",
    "        batch = [remove_non_alphanumeric(name) for name in batch]\n",
    "        emb = model.encode(batch, show_progress_bar=False, convert_to_numpy=True)\n",
    "        embeddings.append(emb)\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings\n",
    "\n",
    "# Fit and Save NearestNeighbors Model\n",
    "# Instance-based learning is a category of machine learning that relies on storing the training data and making predictions based on the direct comparison of new instances with stored data\n",
    "def fit_nearest_neighbors(embeddings, n_neighbors=10, metric='cosine'):\n",
    "    nn_model = NearestNeighbors(n_neighbors=n_neighbors, metric=metric) # non-parametric algorithm used for finding the closest points in a dataset.\n",
    "    nn_model.fit(embeddings) # organizes the embeddings into a structure that allows efficient querying\n",
    "    return nn_model\n",
    "\n",
    "def remove_non_alphanumeric(input_string):\n",
    "    # Use regex to match alphanumeric characters, spaces, points, and commas\n",
    "    return ''.join(re.findall(r'[\\w\\s.,äöüß]', input_string))\n",
    "\n",
    "# Query Function\n",
    "def query_similar_hospitals(target_sentence, model, nn_model, embeddings, hospital_names, top_k=5):\n",
    "    # Compute embedding for the target sentence\n",
    "    target_embedding = model.encode([remove_non_alphanumeric(target_sentence)], convert_to_numpy=True)\n",
    "    \n",
    "    # Perform similarity search with the specified top_k\n",
    "    distances, indices = nn_model.kneighbors(target_embedding, n_neighbors=top_k)\n",
    "    \n",
    "    # Retrieve the hospital names and their similarity scores\n",
    "    results = []\n",
    "    for idx, distance in zip(indices[0], distances[0]):\n",
    "        hospital = hospital_names[idx]  # Directly use the list of hospital names\n",
    "        similarity = 1 - distance  # Convert cosine distance to similarity\n",
    "        results.append((hospital, float(similarity)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Querying for top 10 similar hospitals to 'child_psychiatry':\n",
      "\n",
      "Top similar hospitals:\n",
      "Kinder- und Jugendpsychiatrie (Similarity Score: 0.9098)\n",
      "Facharzt für Kinder-/Jugendpsychiatrie und -psychotherapie (Similarity Score: 0.8957)\n",
      "Praxis für Kinder- und Jugendpsychiatrie (Similarity Score: 0.8881)\n",
      "Praxis für Kinder- und Jugendpsychiatrie und -psychotherapie (Similarity Score: 0.8825)\n",
      "Praxis für Kinderneurologie & Jugendpsychiatrie (Similarity Score: 0.8784)\n",
      "Praxisgemeinschaft Fachärzte für Kinder- und Jugendpsychiatrie und -psychotherapie (Similarity Score: 0.8766)\n",
      "Praxis für Kinder- und Jugendpsychiatrie, –psychosomatik und –psychotherapie (Similarity Score: 0.8731)\n",
      "Facharztpraxis für Kinder- und Jugendpsychiatrie und -psychotherapie (Similarity Score: 0.8696)\n",
      "Kinder- und Jugendpsychiatrische Praxis (Similarity Score: 0.8685)\n",
      "Kinder- und Jugendpsychotherapie (Similarity Score: 0.8656)\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "data_path = '/home/mseiferling/vector_search/data/OpenStreetMap_data/Combined_healthcare_facilities.txt' \n",
    "embeddings_path = '/home/mseiferling/vector_search/data/hospital_embeddings.npy'\n",
    "nearest_neighbors_model_path = '/home/mseiferling/vector_search/data/nearest_neighbors_model.joblib'\n",
    "\n",
    "# model\n",
    "embedding_model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "\n",
    "# Check if embeddings and model already exist\n",
    "if os.path.exists(embeddings_path) and os.path.exists(nearest_neighbors_model_path):\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    nn_model = joblib.load(nearest_neighbors_model_path)\n",
    "    model = SentenceTransformer(embedding_model_name)\n",
    "    hospital_names = load_hospital_names(data_path)\n",
    "else:\n",
    "    # Load hospital names\n",
    "    hospital_names = load_hospital_names(data_path)\n",
    "    \n",
    "    # Load embedding model\n",
    "    model = SentenceTransformer(embedding_model_name)\n",
    "    \n",
    "    # Compute embeddings\n",
    "    embeddings = compute_embeddings(model, hospital_names)\n",
    "    \n",
    "    # Save embeddings\n",
    "    np.save(embeddings_path, embeddings)\n",
    "    \n",
    "    # Fit NearestNeighbors model\n",
    "    nn_model = fit_nearest_neighbors(embeddings, n_neighbors=10, metric='cosine')\n",
    "    \n",
    "    # Save NearestNeighbors model\n",
    "    joblib.dump(nn_model, nearest_neighbors_model_path)\n",
    "\n",
    "# Query\n",
    "target_word = \"child_psychiatry\"\n",
    "top_k = 10 \n",
    "\n",
    "print(f\"\\nQuerying for top {top_k} similar hospitals to '{target_word}':\")\n",
    "results = query_similar_hospitals(target_word, model, nn_model, embeddings, hospital_names, top_k=top_k)\n",
    "\n",
    "# remove if the surrogate is the same => similarity = 1\n",
    "results = [result for result in results if result[1]!= 1] \n",
    "\n",
    "print(\"\\nTop similar hospitals:\")\n",
    "for hospital, score in results:\n",
    "    print(f\"{hospital} (Similarity Score: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Hospital: Dr. med. P. Müller - Chirurg\n",
      "Probabilities associated with each hospital:\n",
      "Facharzt Michael Müller (Probability: 0.1015)\n",
      "Krankengymnastik-Praxis Müller (Probability: 0.1005)\n",
      "Praxis Dr. Müller (Probability: 0.1001)\n",
      "Dr.med. C. Müller HNO (Probability: 0.0999)\n",
      "Hausarzt Mathias Müller (Probability: 0.0999)\n",
      "Dr. med. P. Müller - Chirurg (Probability: 0.0998)\n",
      "Facharzt für Orthopädie Bertram Müller (Probability: 0.0997)\n",
      "Arztpraxis Christoph Müller (Probability: 0.0996)\n",
      "Dr. Richard Müller (Orthopädie) (Probability: 0.0995)\n",
      "Kinderarzt Dr. Müller (Probability: 0.0994)\n"
     ]
    }
   ],
   "source": [
    "# Extract the scores\n",
    "scores = np.array([score for _ , score in results])\n",
    "\n",
    "# Apply sigmoid function to the scores\n",
    "sigmoid_scores = 1 / (1 + np.exp(-scores))\n",
    "\n",
    "# Normalize the probabilities to sum to 1\n",
    "probabilities = sigmoid_scores / np.sum(sigmoid_scores)\n",
    "\n",
    "# Sample one of the hospitals using these probabilities\n",
    "sampled_hospital = str(np.random.choice([hospital for hospital, _ in results], p=probabilities))\n",
    "\n",
    "# Output the sampled hospital and the probabilities\n",
    "print(f\"Sampled Hospital: {sampled_hospital}\")\n",
    "print(\"Probabilities associated with each hospital:\")\n",
    "for (hospital, score), prob in zip(results, probabilities):\n",
    "    print(f\"{hospital} (Probability: {prob:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target sensitive data: ['Müller']\n",
      "Sampled hospital sensitive data: ['P.', 'Müller']\n",
      "Average normalized Levenshtein distance: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "# Load the SpaCy German model for NER and POS tagging\n",
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "\n",
    "# Function to extract proper nouns and named entities\n",
    "def extract_sensitive_data(text):\n",
    "    doc = nlp(text)\n",
    "    unique_substrings = set()\n",
    "\n",
    "    # Extract named entities of type PERSON, ORG, LOC and proper nouns\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"PER\", \"ORG\", \"LOC\"]:  # PERSON, ORGANIZATION, LOCATION\n",
    "            words = ent.text.split()  # Split ent.text into individual words\n",
    "            unique_substrings.update(words) # Add each word to the set\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PROPN\":  # Proper Noun (e.g., specific names)\n",
    "            unique_substrings.add(token.text)\n",
    "\n",
    "    return list(unique_substrings)\n",
    "\n",
    "# Function to normalize Levenshtein distance\n",
    "def normalize_levenshtein_distance(str1, str2):\n",
    "    lev_distance = levenshtein_distance(str1, str2)\n",
    "    max_len = max(len(str1), len(str2))\n",
    "    if max_len == 0:  # To handle edge cases with empty strings\n",
    "        return 0.0\n",
    "    return lev_distance / max_len  # Normalize by dividing by max string length\n",
    "\n",
    "# Function to calculate average Levenshtein distance\n",
    "def calculate_average_distance(target_sensitive_data, sampled_sensitive_data):\n",
    "    total_distance = 0\n",
    "    num_comparisons = len(target_sensitive_data)\n",
    "    \n",
    "    # For each sensitive substring in the target word, find the closest match in the sampled hospital\n",
    "    for target_substring in target_sensitive_data:\n",
    "        min_distance = float('inf')  # Start with a large number\n",
    "        \n",
    "        for sampled_substring in sampled_sensitive_data:\n",
    "            normalized_distance = normalize_levenshtein_distance(target_substring, sampled_substring)\n",
    "            if normalized_distance < min_distance:\n",
    "                min_distance = normalized_distance\n",
    "\n",
    "        # Accumulate the smallest distance for this target substring\n",
    "        total_distance += min_distance\n",
    "\n",
    "    # Calculate the average normalized distance\n",
    "    if num_comparisons == 0:\n",
    "        return 0.0\n",
    "    return total_distance / num_comparisons\n",
    "\n",
    "\n",
    "# inputs\n",
    "# target_word = \"Urologie im 'Käthchenhof' Dr. Schönau\"\n",
    "# sampled_hospital = \"Urologie im Käthhof dr. Schönstein\"\n",
    "\n",
    "# Extract sensitive data from both texts\n",
    "target_sensitive_data = extract_sensitive_data(target_word)\n",
    "sampled_sensitive_data = extract_sensitive_data(sampled_hospital)\n",
    "\n",
    "# Calculate the average normalized Levenshtein distance\n",
    "average_distance = calculate_average_distance(target_sensitive_data, sampled_sensitive_data)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Target sensitive data: {target_sensitive_data}\")\n",
    "print(f\"Sampled hospital sensitive data: {sampled_sensitive_data}\")\n",
    "print(f\"Average normalized Levenshtein distance: {average_distance:.4f}\") # can be interpreted as percentage difference of characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Between Semantic Similarity Approach and Random Sampling:\n",
    "\n",
    "**Objective:**\n",
    "To demonstrate that using a semantic similarity-based approach for data extraction—specifically for identifying and preserving the meaning of semantic categories like \"hospital\"—is more effective than random sampling, both in terms of preserving utility and maintaining anonymity.\n",
    "\n",
    "**Approach:**\n",
    "\n",
    "1. **Semantic Similarity Approach:**\n",
    "   - **Keyword-Based Selection:** Using predefined keywords to generate a list of semantically related hospitals.\n",
    "   - **Annotation and Marking:** Identifying and marking terms that semantically relate to hospitals within the dataset.\n",
    "   - **Preservation of Meaning:** Ensuring that terms related to the \"hospital\" category retain their semantic information during data selection or anonymization.\n",
    "\n",
    "2. **Random Sampling Approach:**\n",
    "   - **Random Selection:** Extracting a random subset of the dataset without considering semantic similarity.\n",
    "   - **Loss of Information:** Risk of losing key terms or relationships that are important to the category \"hospital,\" resulting in decreased utility.\n",
    "\n",
    "---\n",
    "anonymity and utility evaluation\n",
    "utility - preserve semantic meaning?\n",
    "anonymity - if one is sampled how likely is it to sample the original one again? \n",
    "-------\n",
    "Könnten Stations namen in Hospital Location Annotation vorkommen? \n",
    "Falls ja wäre das nicht vom jetztigen datensatz abgedeckt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FA – Facharzt\n",
    "Gyn – Gynäkologe: \n",
    "Uro – Urologe: \n",
    "Derm – Dermatologe: \n",
    "Päd – Pädiater: \n",
    "Radi – Radiologe: \n",
    "Neuro – Neurologe: \n",
    "Psych – Psychologe\n",
    "ZA - Zahnarzt\n",
    "\n",
    "KH – Krankenhaus\n",
    "LKH - Landeskrankenhaus\n",
    "MVZ – Medizinisches Versorgungszentrum\n",
    "ZMVZ - Zahnmedizinisches Versorgungszentrum \n",
    "PHV - patientenheimversorgung\n",
    "ZAR - Zentrum für ambulante Rehabilitation\n",
    "KJPP - Kinder- und Jugendpsychiatrie und Psychotherapie\n",
    "UK – Universitätsklinikum\n",
    "BG – Berufsgenossenschaftliches Krankenhaus\n",
    "REHA – Rehabilitationsklinik\n",
    "KHB – Krankenhausbetriebsgesellschaft\n",
    "SPZ – Sozialpädiatrisches Zentrum\n",
    "EVK – Evangelisches Krankenhaus\n",
    "CVK – Christliches Krankenhaus\n",
    "DRK – Deutsches Rotes Kreuz\n",
    "VKK – Verbundkrankenhaus\n",
    "MLK – Malteser Krankenhaus\n",
    "KFO – Kieferorthopädische Fachklinik\n",
    "ZPM – Zentrum für Psychische Gesundheit\n",
    "ZNA – Zentrale Notaufnahme\n",
    "KFH – Kuratorium für Dialyse und Nierentransplantation\n",
    "PKV – Privatklinik für Versicherte\n",
    "\n",
    "Preprocessing of Query and Hospital Data\n",
    "Add healthcare:specialty information to hospital data embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import overpy\n",
    "\n",
    "# Initialize the Overpass API\n",
    "api = overpy.Overpass() # Read Only connection to OpenStreetMap\n",
    "\n",
    "# Overpass QL query to get all relevant healthcare facilities in Germany\n",
    "overpass_query = \"\"\"\n",
    "[out:json][timeout:180];\n",
    "area[\"ISO3166-1\"=\"DE\"][admin_level=2];\n",
    "(\n",
    "  // Healthcare facilities\n",
    "  node[\"healthcare\"](area);\n",
    "  way[\"healthcare\"](area);\n",
    "  relation[\"healthcare\"](area);\n",
    ");\n",
    "out body;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the Overpass query\n",
    "result = api.query(overpass_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for node in result.nodes:\n",
    "#     print(node.tags)\n",
    "    \n",
    "#     healthcare:speciality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
