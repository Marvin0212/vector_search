{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mseiferling/.venvs/vector/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# Liste der Abkürzungen für medizinische Einrichtungen und Geschäftliche Formen\n",
    "abbreviations = {\n",
    "    # Medizinische Fachbereiche und Einrichtungen\n",
    "    \"HNO\": \"Hals-Nasen-Ohren\",\n",
    "    \"MKG\": \"Mund-, Kiefer- und Gesichtschirurgie\",\n",
    "    \"FA\": \"Facharzt\",\n",
    "    \"ZA\": \"Zahnarzt\",\n",
    "    \"KH\": \"Krankenhaus\",\n",
    "    \"LKH\": \"Landeskrankenhaus\",\n",
    "    \"MVZ\": \"Medizinisches Versorgungszentrum\",\n",
    "    \"ZMVZ\": \"Zahnmedizinisches Versorgungszentrum\",\n",
    "    \"PHV\": \"Patientenheimversorgung\",\n",
    "    \"ZAR\": \"Zentrum für ambulante Rehabilitation\",\n",
    "    \"KJPP\": \"Kinder- und Jugendpsychiatrie und Psychotherapie\",\n",
    "    \"UK\": \"Universitätsklinikum\",\n",
    "    \"BG\": \"Berufsgenossenschaftliches Krankenhaus\",\n",
    "    \"REHA\": \"Rehabilitationsklinik\",\n",
    "    \"KG\": \"Krankengymnastik\",\n",
    "    \"KHB\": \"Krankenhausbetriebsgesellschaft\",\n",
    "    \"SPZ\": \"Sozialpädiatrisches Zentrum\",\n",
    "    \"EVK\": \"Evangelisches Krankenhaus\",\n",
    "    \"CVK\": \"Christliches Krankenhaus\",\n",
    "    \"DRK\": \"Deutsches Rotes Kreuz\",\n",
    "    \"VKK\": \"Verbundkrankenhaus\",\n",
    "    \"MLK\": \"Malteser Krankenhaus\",\n",
    "    \"KFO\": \"Kieferorthopädische Fachklinik\",\n",
    "    \"ZPM\": \"Zentrum für Psychische Gesundheit\",\n",
    "    \"ZNA\": \"Zentrale Notaufnahme\",\n",
    "    \"KFH\": \"Kuratorium für Dialyse und Nierentransplantation\",\n",
    "    \"PKV\": \"Privatklinik für Versicherte\",\n",
    "    \n",
    "    # Geschäftliche Rechtsformen\n",
    "    \"e.V.\": \"Eingetragener Verein\",\n",
    "    \"GmbH\": \"Gesellschaft mit beschränkter Haftung\",\n",
    "    \"KGaA\": \"Kommanditgesellschaft auf Aktien\",\n",
    "    \"GmbH & Co. KG\": \"Kombination aus GmbH und Kommanditgesellschaft\",\n",
    "    \"GbR\": \"Gesellschaft bürgerlichen Rechts\",\n",
    "    \"AG\": \"Aktiengesellschaft\",\n",
    "    \"OHG\": \"Offene Handelsgesellschaft\",\n",
    "    \"SE\": \"Europäische Aktiengesellschaft\",\n",
    "    \"PartG\": \"Partnerschaftsgesellschaft\",\n",
    "    \"PartGmbB\": \"Partnerschaftsgesellschaft mit beschränkter Berufshaftung\",\n",
    "}\n",
    "\n",
    "# Funktion zum Erstellen des regulären Ausdrucks und zum Ersetzen der Abkürzungen\n",
    "def replace_abbreviation(text, abbreviations):\n",
    "    # Precompiled regular expression pattern to match any of the abbreviations\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in abbreviations.keys()) + r')\\b')\n",
    "    # Replace abbreviations in the text using the dictionary\n",
    "    return pattern.sub(lambda x: abbreviations[x.group()], text)\n",
    "\n",
    "def remove_non_alphanumeric(input_string):\n",
    "    # Use regex to match alphanumeric characters, spaces, points, and commas\n",
    "    return ''.join(re.findall(r'[\\w\\s.,äöüß/]', input_string))\n",
    "\n",
    "# Compute Embeddings\n",
    "def compute_embeddings(model, sentences, batch_size=512):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Computing Embeddings\"):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        # Apply abbreviation replacement and remove non-alphanumeric characters\n",
    "        batch = [remove_non_alphanumeric(replace_abbreviation(name, abbreviations)) for name in batch]\n",
    "        emb = model.encode(batch, show_progress_bar=False, convert_to_numpy=True)\n",
    "        embeddings.append(emb)\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings\n",
    "\n",
    "# Load hospital Names from a Text File\n",
    "def load_hospital_names(text_file):\n",
    "    with open(text_file, 'r', encoding='utf-8') as f:\n",
    "        hospital_names = [line.strip() for line in f if line.strip()]\n",
    "    return hospital_names\n",
    "\n",
    "# Fit and Save NearestNeighbors Model\n",
    "# Instance-based learning is a category of machine learning that relies on storing the training data and making predictions based on the direct comparison of new instances with stored data\n",
    "def fit_nearest_neighbors(embeddings, n_neighbors=10, metric='cosine'):\n",
    "    nn_model = NearestNeighbors(n_neighbors=n_neighbors, metric=metric) # non-parametric algorithm used for finding the closest points in a dataset.\n",
    "    nn_model.fit(embeddings) # organizes the embeddings into a structure that allows efficient querying\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Paths\n",
    "data_path = '/home/mseiferling/vector_search/data/OpenStreetMap_data/Combined_healthcare_facilities.txt' \n",
    "embeddings_path = '/home/mseiferling/vector_search/data/hospital_embeddings.npy'\n",
    "nearest_neighbors_model_path = '/home/mseiferling/vector_search/data/nearest_neighbors_model.joblib'\n",
    "\n",
    "# model\n",
    "embedding_model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "\n",
    "# Check if embeddings and model already exist\n",
    "if os.path.exists(embeddings_path) and os.path.exists(nearest_neighbors_model_path):\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    nn_model = joblib.load(nearest_neighbors_model_path)\n",
    "    model = SentenceTransformer(embedding_model_name)\n",
    "    hospital_names = load_hospital_names(data_path)\n",
    "else:\n",
    "    # Load hospital names\n",
    "    hospital_names = load_hospital_names(data_path)\n",
    "    \n",
    "    # Load embedding model\n",
    "    model = SentenceTransformer(embedding_model_name)\n",
    "    \n",
    "    # Compute embeddings\n",
    "    embeddings = compute_embeddings(model, hospital_names)\n",
    "    \n",
    "    # Save embeddings\n",
    "    np.save(embeddings_path, embeddings)\n",
    "    \n",
    "    # Fit NearestNeighbors model\n",
    "    nn_model = fit_nearest_neighbors(embeddings, n_neighbors=10, metric='cosine')\n",
    "    \n",
    "    # Save NearestNeighbors model\n",
    "    joblib.dump(nn_model, nearest_neighbors_model_path)\n",
    "    \n",
    "    # Load the SpaCy German model for NER and POS tagging\n",
    "    nlp = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search expanded to k=10\n",
      "\n",
      "Sampled Hospital: Universitätsklinikum Aachen\n",
      "Probabilities associated with each hospital:\n",
      "Universitätsklinikum Frankfurt (Probability: 0.1514)\n",
      "Universitätsklinikum Düsseldorf (Probability: 0.1514)\n",
      "Universitätsklinikum Augsburg (Probability: 0.1514)\n",
      "Universitätsklinikum Freiburg (Probability: 0.1514)\n",
      "Universitätsklinikum Hamburg-Eppendorf (Probability: 0.1514)\n",
      "Universitätsmedizin Göttingen (Probability: 0.0918)\n",
      "Universitätsklinikum Aachen (Probability: 0.1514)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "import logging\n",
    "import re\n",
    "\n",
    "# Liste der Abkürzungen für medizinische Einrichtungen und Geschäftliche Formen\n",
    "abbreviations = {\n",
    "    # Medizinische Fachbereiche und Einrichtungen\n",
    "    \"HNO\": \"Hals-Nasen-Ohren\",\n",
    "    \"MKG\": \"Mund-, Kiefer- und Gesichtschirurgie\",\n",
    "    \"FA\": \"Facharzt\",\n",
    "    \"ZA\": \"Zahnarzt\",\n",
    "    \"KH\": \"Krankenhaus\",\n",
    "    \"LKH\": \"Landeskrankenhaus\",\n",
    "    \"MVZ\": \"Medizinisches Versorgungszentrum\",\n",
    "    \"ZMVZ\": \"Zahnmedizinisches Versorgungszentrum\",\n",
    "    \"PHV\": \"Patientenheimversorgung\",\n",
    "    \"ZAR\": \"Zentrum für ambulante Rehabilitation\",\n",
    "    \"KJPP\": \"Kinder- und Jugendpsychiatrie und Psychotherapie\",\n",
    "    \"UK\": \"Universitätsklinikum\",\n",
    "    \"BG\": \"Berufsgenossenschaftliches Krankenhaus\",\n",
    "    \"REHA\": \"Rehabilitationsklinik\",\n",
    "    \"KG\": \"Krankengymnastik\",\n",
    "    \"KHB\": \"Krankenhausbetriebsgesellschaft\",\n",
    "    \"SPZ\": \"Sozialpädiatrisches Zentrum\",\n",
    "    \"EVK\": \"Evangelisches Krankenhaus\",\n",
    "    \"CVK\": \"Christliches Krankenhaus\",\n",
    "    \"DRK\": \"Deutsches Rotes Kreuz\",\n",
    "    \"VKK\": \"Verbundkrankenhaus\",\n",
    "    \"MLK\": \"Malteser Krankenhaus\",\n",
    "    \"KFO\": \"Kieferorthopädische Fachklinik\",\n",
    "    \"ZPM\": \"Zentrum für Psychische Gesundheit\",\n",
    "    \"ZNA\": \"Zentrale Notaufnahme\",\n",
    "    \"KFH\": \"Kuratorium für Dialyse und Nierentransplantation\",\n",
    "    \"PKV\": \"Privatklinik für Versicherte\",\n",
    "    \n",
    "    # Geschäftliche Rechtsformen\n",
    "    \"e.V.\": \"Eingetragener Verein\",\n",
    "    \"GmbH\": \"Gesellschaft mit beschränkter Haftung\",\n",
    "    \"KGaA\": \"Kommanditgesellschaft auf Aktien\",\n",
    "    \"GmbH & Co. KG\": \"Kombination aus GmbH und Kommanditgesellschaft\",\n",
    "    \"GbR\": \"Gesellschaft bürgerlichen Rechts\",\n",
    "    \"AG\": \"Aktiengesellschaft\",\n",
    "    \"OHG\": \"Offene Handelsgesellschaft\",\n",
    "    \"SE\": \"Europäische Aktiengesellschaft\",\n",
    "    \"PartG\": \"Partnerschaftsgesellschaft\",\n",
    "    \"PartGmbB\": \"Partnerschaftsgesellschaft mit beschränkter Berufshaftung\",\n",
    "}\n",
    "\n",
    "# List of substrings to search for\n",
    "healthcare_keywords = [\n",
    "    # Allgemeine Begriffe\n",
    "    \"arzt\", \"ärzt\", \"chirurg\", \"gemeinschaft\", \"klinik\", \"logie\", \"ologe\", \n",
    "    \"medizin\", \"praxis\", \"sanatorium\", \"therapie\", \"ambulanz\", \n",
    "\n",
    "    # Fachrichtungen und Behandlungen\n",
    "    \"anästhesie\", \"augen\", \"cardio\", \"dental\", \"derm\", \"endokrin\", \"gastro\", \"gyn\", \n",
    "    \"hämo\", \"kardio\", \"neuro\", \"onko\", \"optik\", \"ortho\", \"osteo\", \"pathie\", \n",
    "    \"pädie\", \"pneumo\", \"psych\", \"uro\", \"zahn\", \"zähne\",\"internist\",\n",
    "\n",
    "    # Verfahren und Diagnostik\n",
    "    \"blut\", \"ct\", \"diagnostik\", \"echo\", \"labor\", \"mrt\", \"radio\", \"rehabil\", \"spende\",\n",
    "\n",
    "    # Pflege und Behandlungsarten\n",
    "    \"betreuung\", \"ernährung\", \"geriatr\", \"hospiz\", \"intensiv\", \"palliativ\", \"pflege\", \n",
    "    \"physio\", \"rehaklinik\", \"therapeut\",\n",
    "\n",
    "    # Alternative Medizin\n",
    "    \"akupunkt\", \"heilpraktiker\", \"homöo\", \"naturheil\",\n",
    "\n",
    "    # Einrichtungen und Zentren\n",
    "    \"fach\", \"kranken\", \"notfall\", \"reha\", \"zentrum\", \"haus\", \"test\",\n",
    "\n",
    "    # Pädiatrie, Frauen und Spezialversorgung\n",
    "    \"diabetes\", \"frauen\", \"kinder\", \"lungen\",\n",
    "\n",
    "    # Zusätzliche Begriffe\n",
    "    \"apotheke\", \"behandl\", \"chirurgi\", \"gesundheitszentrum\", \n",
    "    \"klinisch\", \"untersuch\",\n",
    "    \n",
    "    # titel\n",
    "    \"dr\",\"phil\",\"univ\",\"medic\",\"dres\",\"med\",\"dipl\",\"psych\",\"dent\",\"vet\",\n",
    "    \n",
    "    #abbreviations\n",
    "    \"hno\", \"mkg\", \"fa\", \"za\", \"kh\", \"lkh\", \"mvz\", \"zmvz\", \"phv\", \"zar\", \"kjpp\", \"uk\", \"bg\", \"reha\", \"kg\", \"khb\", \"spz\", \"evk\", \"cvk\", \"drk\", \"vkk\", \"mlk\", \"kfo\", \"zpm\", \"zna\", \"kfh\", \"pkv\"\n",
    "]\n",
    "\n",
    "# Funktion zum Erstellen des regulären Ausdrucks und zum Ersetzen der Abkürzungen\n",
    "def replace_abbreviation(text, abbreviations):\n",
    "    \"\"\"\n",
    "    Replace abbreviations in a given text with their full forms based on a provided dictionary.\n",
    "\n",
    "    This function searches for any abbreviations specified as keys in the `abbreviations` dictionary\n",
    "    within the `text`. If a match is found, it replaces the abbreviation with its corresponding full\n",
    "    form from the dictionary. The function uses a regular expression with word boundaries to ensure\n",
    "    that only exact abbreviations are matched (i.e., whole words).\n",
    "\n",
    "    Args:\n",
    "    text : str\n",
    "        The input string where abbreviations are to be replaced.\n",
    "        \n",
    "    abbreviations : dict\n",
    "        A dictionary where keys are abbreviations (as strings) and values are their full forms (as strings).\n",
    "        \n",
    "    Returns:\n",
    "    str\n",
    "        The modified text with all found abbreviations replaced by their full forms.\n",
    "    \"\"\"\n",
    "    # Precompiled regular expression pattern to match any of the abbreviations\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in abbreviations.keys()) + r')\\b')\n",
    "    \n",
    "    # Replace abbreviations in the text using the dictionary\n",
    "    return pattern.sub(lambda x: abbreviations[x.group()], text)\n",
    "\n",
    "# helper function to extract the main name before '/'\n",
    "def get_name(facility):\n",
    "    \"\"\"\n",
    "    Extracts the main facility name before any '/' characters.\n",
    "\n",
    "    Parameters:\n",
    "    facility (str): The full facility string containing the name and additional info.\n",
    "\n",
    "    Returns:\n",
    "    str: The main facility name.\n",
    "    \"\"\"\n",
    "    return facility.split('/')[0].strip()\n",
    "\n",
    "def extract_sensitive_data(text, nlp, healthcare_keywords):\n",
    "    \"\"\"\n",
    "    Extract named entities and proper nouns from text, filtering out healthcare-related terms.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to process\n",
    "        healthcare_keywords (list): List of healthcare-related keywords to filter out.\n",
    "    \n",
    "    Returns:\n",
    "        list: Filtered list of unique sensitive words\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    unique_substrings = set()\n",
    "    \n",
    "    # Extract named entities of type PERSON, ORG, LOC and proper nouns\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"PER\", \"ORG\", \"LOC\"]:\n",
    "            words = ent.text.split()\n",
    "            # Only add words that don't contain healthcare keywords\n",
    "            filtered_words = [\n",
    "                word for word in words \n",
    "                if not any(keyword in word.lower() for keyword in healthcare_keywords)\n",
    "            ]\n",
    "            unique_substrings.update(filtered_words)\n",
    "    \n",
    "    # Extract proper nouns\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PROPN\":\n",
    "            # Only add if it doesn't contain healthcare keywords\n",
    "            if not any(keyword in token.text.lower() for keyword in healthcare_keywords):\n",
    "                unique_substrings.add(token.text)\n",
    "    \n",
    "    return list(unique_substrings)\n",
    "\n",
    "def filter_hospitals(hospitals, similarity_scores, sensitive_words):\n",
    "    \"\"\"\n",
    "    Filter hospitals based on similarity scores and sensitive words.\n",
    "    \n",
    "    Args:\n",
    "        hospitals (list): List of hospital names to filter\n",
    "        similarity_scores (list): List of similarity scores corresponding to each hospital\n",
    "        sensitive_words (list): List of sensitive words to filter out\n",
    "    \n",
    "    Returns:\n",
    "        list: Filtered list of hospitals excluding exact matches and those containing sensitive words\n",
    "    \"\"\"\n",
    "    # Combine the filtering conditions into a single list comprehension\n",
    "    filtered_hospitals = [\n",
    "        hospital for hospital, score in zip(hospitals, similarity_scores)\n",
    "        if score != 1 and not any(\n",
    "            sensitive_word.lower() in hospital.lower() \n",
    "            for sensitive_word in sensitive_words\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return filtered_hospitals\n",
    "\n",
    "def normalize_levenshtein_distance(str1, str2):\n",
    "    \"\"\"\n",
    "    Calculate the normalized Levenshtein distance between two strings.\n",
    "\n",
    "    The normalized Levenshtein distance is the ratio of the raw Levenshtein distance to the\n",
    "    length of the longer string, providing a similarity measure between 0 and 1. A result\n",
    "    closer to 0 indicates higher similarity, while a result closer to 1 indicates more dissimilarity.\n",
    "\n",
    "    Args:\n",
    "    str1 (str): The first string to compare.\n",
    "    str2 (str): The second string to compare.\n",
    "\n",
    "    Returns:\n",
    "    float: The normalized Levenshtein distance, ranging from 0.0 to 1.0.\n",
    "           Returns 0.0 for two empty strings (an edge case).\n",
    "    \"\"\"\n",
    "    lev_distance = levenshtein_distance(str1, str2)\n",
    "    max_len = max(len(str1), len(str2))\n",
    "    if max_len == 0:  # Handle edge case with empty strings\n",
    "        return 0.0\n",
    "    return lev_distance / max_len  # Normalize by dividing by the max string length\n",
    "\n",
    "\n",
    "def calculate_average_distance(target_sensitive_data, sampled_sensitive_data):\n",
    "    \"\"\"\n",
    "    Calculate the average normalized Levenshtein distance between target terms and sampled terms.\n",
    "\n",
    "    For each word in the target terms, find the closest matching word in the sampled terms,\n",
    "    and compute the normalized Levenshtein distance between them. The average of these\n",
    "    minimum distances is returned, adjusted to produce a similarity measure from 0 to 1,\n",
    "    where higher values indicate greater similarity.\n",
    "\n",
    "    Args:\n",
    "    target_sensitive_data (list of str): List of target terms (e.g., words related to healthcare in the target hospital).\n",
    "    sampled_sensitive_data (list of str): List of terms from a hospital name to compare against the target terms.\n",
    "\n",
    "    Returns:\n",
    "    float: The average normalized Levenshtein distance, where 1 indicates perfect similarity\n",
    "           and values closer to 0 indicate dissimilarity.\n",
    "    \"\"\"\n",
    "    total_distance = 0\n",
    "    num_comparisons = len(target_sensitive_data)\n",
    "    \n",
    "    # For each target term, find the closest match in the sampled terms\n",
    "    for target_substring in target_sensitive_data:\n",
    "        min_distance = float('inf')  # Initialize with a large value\n",
    "        \n",
    "        for sampled_substring in sampled_sensitive_data:\n",
    "            normalized_distance = normalize_levenshtein_distance(target_substring.lower(), sampled_substring.lower())\n",
    "            if normalized_distance < min_distance:\n",
    "                min_distance = normalized_distance\n",
    "\n",
    "        # Accumulate the smallest distance for this target term\n",
    "        total_distance += min_distance\n",
    "\n",
    "    # Calculate the average normalized distance\n",
    "    if num_comparisons == 0:\n",
    "        return 0.0\n",
    "    return 1 - (total_distance / num_comparisons)\n",
    "\n",
    "\n",
    "def calculate_hospital_probabilities(ranked_hospitals, temperature=0.1):\n",
    "    \"\"\"\n",
    "    Calculate a probability distribution over hospitals based on their distances using a sigmoid function and temperature scaling.\n",
    "\n",
    "    Args:\n",
    "    ranked_hospitals (list of tuples): A list where each element is a tuple of (hospital, distance).\n",
    "    temperature (float): A scaling factor to adjust the sharpness of the probability distribution.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - hospitals (tuple): A tuple of hospital identifiers.\n",
    "        - probabilities (numpy.ndarray): An array of probabilities corresponding to each hospital.\n",
    "    \"\"\"\n",
    "    # Split the hospitals and distances\n",
    "    hospitals, distances = zip(*ranked_hospitals)\n",
    "    distances = np.array(distances)\n",
    "    \n",
    "    # Apply sigmoid function to distances\n",
    "    sigmoid_distances = 1 / (1 + np.exp(-distances))\n",
    "    \n",
    "    # Apply temperature scaling to make the distribution sharper\n",
    "    scaled_scores = sigmoid_distances ** (1 / temperature)\n",
    "    \n",
    "    # Normalize the scaled scores to create a probability distribution\n",
    "    probabilities = scaled_scores / np.sum(scaled_scores)\n",
    "    \n",
    "    return hospitals, probabilities\n",
    "\n",
    "def rank_hospitals_by_similarity(target_hospital, filtered_hospitals, healthcare_keywords):\n",
    "    \"\"\"\n",
    "    Identify and rank hospitals based on the similarity of healthcare-related terms in the target hospital name.\n",
    "\n",
    "    Args:\n",
    "    target_hospital (str): The name of the target hospital to compare against.\n",
    "    filtered_hospitals (list of str): A list of hospital names to be evaluated.\n",
    "    healthcare_keywords (list of str): A list of keywords representing healthcare-related terms.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: A list of tuples where each tuple contains a hospital name and its average normalized\n",
    "                    Levenshtein distance to the healthcare-related terms in the target hospital. Only hospitals\n",
    "                    with an average distance above or equal to 0.5 are included.\n",
    "    \"\"\"\n",
    "    # Extract healthcare-related words from the target hospital name\n",
    "    healthcare_terms = [word for word in re.split(r'[ \\-]', target_hospital) if any(keyword in word.lower() for keyword in healthcare_keywords)]\n",
    "    ranked_hospitals = []\n",
    "    \n",
    "    # Calculate average normalized Levenshtein distance and filter hospitals\n",
    "    for hospital in filtered_hospitals:\n",
    "        avg_distance = calculate_average_distance(healthcare_terms, re.split(r'[ \\-]', hospital))\n",
    "        # print(hospital.split(),avg_distance)\n",
    "        if avg_distance >= 0.5:\n",
    "            ranked_hospitals.append((hospital, avg_distance))\n",
    "    \n",
    "    return ranked_hospitals\n",
    "\n",
    "def query_similar_hospitals(target_sentence, model, nn_model, hospital_names, top_k=5):\n",
    "    # Compute embedding for the target sentence\n",
    "    target_embedding = model.encode([remove_non_alphanumeric(target_sentence)], convert_to_numpy=True)\n",
    "    \n",
    "    # Perform similarity search with the specified top_k\n",
    "    distances, indices = nn_model.kneighbors(target_embedding, n_neighbors=top_k)\n",
    "    \n",
    "    # Retrieve the hospital names and their similarity scores\n",
    "    results = []\n",
    "    similarity = []\n",
    "    for idx, distance in zip(indices[0], distances[0]):\n",
    "        hospital = hospital_names[idx]  # Directly use the list of hospital names\n",
    "        similarity_score = 1 - distance  # Convert cosine distance to similarity\n",
    "        results.append(hospital)\n",
    "        similarity.append(float(similarity_score))\n",
    "    return results, similarity\n",
    "\n",
    "def query_similar_hospitals_adaptive(target_hospital, model, nn_model, nlp, hospital_names, initial_k=10, max_k=100, step_size=10, min_matches=3):\n",
    "    \"\"\"\n",
    "    Adaptively queries for similar hospitals, expanding the search until enough matches are found.\n",
    "    \n",
    "    Args:\n",
    "        target_hospital (str): The hospital to find matches for\n",
    "        model: The embedding model\n",
    "        nn_model: The nearest neighbor model\n",
    "        hospital_names (list): List of all hospital names\n",
    "        initial_k (int): Initial number of hospitals to retrieve\n",
    "        max_k (int): Maximum number of hospitals to consider\n",
    "        step_size (int): How much to increase k by in each iteration\n",
    "        min_matches (int): Minimum number of matches required\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (filtered_hospitals, similarity_scores, k_used)\n",
    "    \"\"\"\n",
    "    current_k = initial_k\n",
    "    \n",
    "    while current_k <= max_k:\n",
    "        # replace abbreviation with the semantic full form\n",
    "        target_hospital_extended = replace_abbreviation(target_hospital, abbreviations)\n",
    "        \n",
    "        # Get similar hospitals with current k\n",
    "        similar_hospitals, similarity_scores = query_similar_hospitals(target_hospital_extended, model, nn_model, hospital_names, top_k=current_k)\n",
    "        \n",
    "        # Apply the get_name function to each similar hospital to remove the healthcare:specialty infromation\n",
    "        similar_hospitals = [get_name(hospital) for hospital in similar_hospitals]\n",
    "        #print(similar_hospitals)\n",
    "        # Extract sensitive words\n",
    "        sensitive_words = extract_sensitive_data(target_hospital_extended, nlp, healthcare_keywords)\n",
    "        #print(sensitive_words)\n",
    "        # Filter hospitals\n",
    "        filtered_hospitals = filter_hospitals(similar_hospitals, similarity_scores, sensitive_words)\n",
    "        # If we have enough matches, break\n",
    "        if len(filtered_hospitals) >= min_matches:\n",
    "            return filtered_hospitals, current_k\n",
    "            \n",
    "        # Increase k for next iteration\n",
    "        current_k += step_size\n",
    "        \n",
    "        logging.info(f\"Insufficient matches found with k={current_k-step_size}, \"\n",
    "                    f\"expanding search to k={current_k}\")\n",
    "    \n",
    "    # If we get here, we couldn't find enough matches even with max_k\n",
    "    logging.warning(f\"Could not find {min_matches} matches even with k={max_k}\")\n",
    "    \n",
    "    return filtered_hospitals, current_k\n",
    "\n",
    "def get_hospital_surrogate(target_hospital, model, nn_model, nlp, hospital_names, healthcare_keywords, initial_k = 10, max_k = 100, min_matches = 3):\n",
    "    \"\"\"\n",
    "    Main function to get a surrogate hospital with adaptive search.\n",
    "    \n",
    "    Args:\n",
    "        target_hospital (str): The hospital to find matches for\n",
    "        model: The embedding model\n",
    "        nn_model: The nearest neighbor model\n",
    "        hospital_names (list): List of all hospital names\n",
    "        initial_k (int): Initial number of hospitals to retrieve\n",
    "        max_k (int): Maximum number of hospitals to consider\n",
    "        min_matches (int): Minimum number of matches required\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (sampled_hospital, probabilities, hospitals, k_used)\n",
    "    \"\"\"\n",
    "    # Get similar hospitals with adaptive k search\n",
    "    similar_hospitals, k_used = query_similar_hospitals_adaptive(target_hospital, model, nn_model, nlp, hospital_names, initial_k=initial_k, max_k=max_k, min_matches=min_matches)\n",
    "    # Rank hospitals\n",
    "    ranked_hospitals = rank_hospitals_by_similarity(target_hospital, similar_hospitals, healthcare_keywords)\n",
    "    # Calculate probabilities and sample\n",
    "    hospitals, probabilities = calculate_hospital_probabilities(ranked_hospitals)\n",
    "    sampled_hospital = np.random.choice(hospitals, p=probabilities)\n",
    "    \n",
    "    return sampled_hospital, probabilities, hospitals, k_used\n",
    "\n",
    "\n",
    "# example Usage\n",
    "target_hospital = \"Universitätsklinik Heidelberg\"\n",
    "surrogate_hospital, probabilities, hospitals, k_used = get_hospital_surrogate(target_hospital, model, nn_model, nlp, hospital_names, healthcare_keywords)\n",
    "    \n",
    "print(f\"\\nSearch expanded to k={k_used}\")\n",
    "print(f\"\\nSampled Hospital: {surrogate_hospital}\")\n",
    "print(\"Probabilities associated with each hospital:\")\n",
    "for hospital, probability in zip(hospitals, probabilities):\n",
    "    print(f\"{hospital} (Probability: {probability:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hals-Nasen-Ohren Privat-Praxis Dr. Ingo Reimold\n",
      "Mund-, Kiefer- und Gesichtschirurgie Spezialist Dr. Fischer\n",
      "Berufsgenossenschaftliches Krankenhaus Klinik in der Nähe\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Liste der Abkürzungen für medizinische Einrichtungen und Geschäftliche Formen\n",
    "abbreviations = {\n",
    "    # Medizinische Fachbereiche und Einrichtungen\n",
    "    \"HNO\": \"Hals-Nasen-Ohren\",\n",
    "    \"MKG\": \"Mund-, Kiefer- und Gesichtschirurgie\",\n",
    "    \"FA\": \"Facharzt\",\n",
    "    \"ZA\": \"Zahnarzt\",\n",
    "    \"KH\": \"Krankenhaus\",\n",
    "    \"LKH\": \"Landeskrankenhaus\",\n",
    "    \"MVZ\": \"Medizinisches Versorgungszentrum\",\n",
    "    \"ZMVZ\": \"Zahnmedizinisches Versorgungszentrum\",\n",
    "    \"PHV\": \"Patientenheimversorgung\",\n",
    "    \"ZAR\": \"Zentrum für ambulante Rehabilitation\",\n",
    "    \"KJPP\": \"Kinder- und Jugendpsychiatrie und Psychotherapie\",\n",
    "    \"UK\": \"Universitätsklinikum\",\n",
    "    \"BG\": \"Berufsgenossenschaftliches Krankenhaus\",\n",
    "    \"REHA\": \"Rehabilitationsklinik\",\n",
    "    \"KG\": \"Krankengymnastik\",\n",
    "    \"KHB\": \"Krankenhausbetriebsgesellschaft\",\n",
    "    \"SPZ\": \"Sozialpädiatrisches Zentrum\",\n",
    "    \"EVK\": \"Evangelisches Krankenhaus\",\n",
    "    \"CVK\": \"Christliches Krankenhaus\",\n",
    "    \"DRK\": \"Deutsches Rotes Kreuz\",\n",
    "    \"VKK\": \"Verbundkrankenhaus\",\n",
    "    \"MLK\": \"Malteser Krankenhaus\",\n",
    "    \"KFO\": \"Kieferorthopädische Fachklinik\",\n",
    "    \"ZPM\": \"Zentrum für Psychische Gesundheit\",\n",
    "    \"ZNA\": \"Zentrale Notaufnahme\",\n",
    "    \"KFH\": \"Kuratorium für Dialyse und Nierentransplantation\",\n",
    "    \"PKV\": \"Privatklinik für Versicherte\",\n",
    "    \n",
    "    # Geschäftliche Rechtsformen\n",
    "    \"e.V.\": \"Eingetragener Verein\",\n",
    "    \"GmbH\": \"Gesellschaft mit beschränkter Haftung\",\n",
    "    \"KGaA\": \"Kommanditgesellschaft auf Aktien\",\n",
    "    \"GmbH & Co. KG\": \"Kombination aus GmbH und Kommanditgesellschaft\",\n",
    "    \"GbR\": \"Gesellschaft bürgerlichen Rechts\",\n",
    "    \"AG\": \"Aktiengesellschaft\",\n",
    "    \"OHG\": \"Offene Handelsgesellschaft\",\n",
    "    \"SE\": \"Europäische Aktiengesellschaft\",\n",
    "    \"PartG\": \"Partnerschaftsgesellschaft\",\n",
    "    \"PartGmbB\": \"Partnerschaftsgesellschaft mit beschränkter Berufshaftung\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Funktion zum Erstellen des regulären Ausdrucks und zum Ersetzen der Abkürzungen\n",
    "def replace_abbreviation(text, abbreviations):\n",
    "    # Precompiled regular expression pattern to match any of the abbreviations\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in abbreviations.keys()) + r')\\b')\n",
    "    \n",
    "    # Replace abbreviations in the text using the dictionary\n",
    "    return pattern.sub(lambda x: abbreviations[x.group()], text)\n",
    "\n",
    "\n",
    "# List of strings to process\n",
    "texts = [\"HNO Privat-Praxis Dr. Ingo Reimold\", \"MKG Spezialist Dr. Fischer\", \"BG Klinik in der Nähe\"]\n",
    "\n",
    "# Apply the function to each line in texts\n",
    "result = [replace_abbreviation(text, abbreviations) for text in texts]\n",
    "\n",
    "# Display results\n",
    "for line in result:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the following steps ensure no sensitive information is disclosed\n",
    "step 1: remove 1:1 similarity \n",
    "\n",
    "step 2: detect sensitive names using a POS Tagger model from spacy which can detect pROPER NOUNS\n",
    "step 3: remove query results containing THESE sensitve proper noun names\n",
    "\n",
    "# the following steps serve two purposes it increases the likelihood of semantic similiar surrogate and it ensures that the similarity in those top names is based on the healthcare facility and not on the sensitve information decreasing likelihood of choosing sensitive surrogate\n",
    "step 4: detect healthcare names with a list of facility keywords \n",
    "step 5: get top levenshtein distance names with the lowest distance from the query \n",
    "\n",
    "# picking the surrogate\n",
    "step 6: sample from the remaining results which exclude results with sensitve proper nouns and prioritize results with low levenshtein distance to the semnatic relevant healthcase facility names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Between Semantic Similarity Approach and Random Sampling:\n",
    "\n",
    "**Objective:**\n",
    "To demonstrate that using a semantic similarity-based approach for data extraction—specifically for identifying and preserving the meaning of semantic categories like \"hospital\"—is more effective than random sampling, both in terms of preserving utility and maintaining anonymity.\n",
    "\n",
    "**Approach:**\n",
    "\n",
    "1. **Semantic Similarity Approach:**\n",
    "   - **Keyword-Based Selection:** Using predefined keywords to generate a list of semantically related hospitals.\n",
    "   - **Annotation and Marking:** Identifying and marking terms that semantically relate to hospitals within the dataset.\n",
    "   - **Preservation of Meaning:** Ensuring that terms related to the \"hospital\" category retain their semantic information during data selection or anonymization.\n",
    "\n",
    "2. **Random Sampling Approach:**\n",
    "   - **Random Selection:** Extracting a random subset of the dataset without considering semantic similarity.\n",
    "   - **Loss of Information:** Risk of losing key terms or relationships that are important to the category \"hospital,\" resulting in decreased utility.\n",
    "\n",
    "---\n",
    "anonymity and utility evaluation\n",
    "utility - preserve semantic meaning?\n",
    "anonymity - if one is sampled how likely is it to sample the original one again? \n",
    "-------\n",
    "Könnten Stations namen in Hospital Location Annotation vorkommen? \n",
    "Falls ja wäre das nicht vom jetztigen datensatz abgedeckt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HNO - Hals-Nasen-Ohren-Heilkunde\n",
    "MKG - Mund-, Kiefer- und Gesichtschirurgie\n",
    "FA – Facharzt\n",
    "ZA - Zahnarzt\n",
    "KH – Krankenhaus\n",
    "LKH - Landeskrankenhaus\n",
    "MVZ – Medizinisches Versorgungszentrum\n",
    "ZMVZ - Zahnmedizinisches Versorgungszentrum \n",
    "PHV - patientenheimversorgung\n",
    "ZAR - Zentrum für ambulante Rehabilitation\n",
    "KJPP - Kinder- und Jugendpsychiatrie und Psychotherapie\n",
    "UK – Universitätsklinikum\n",
    "BG – Berufsgenossenschaftliches Krankenhaus\n",
    "REHA – Rehabilitationsklinik\n",
    "KG - Krankengymnastik\n",
    "KHB – Krankenhausbetriebsgesellschaft\n",
    "SPZ – Sozialpädiatrisches Zentrum\n",
    "EVK – Evangelisches Krankenhaus\n",
    "CVK – Christliches Krankenhaus\n",
    "DRK – Deutsches Rotes Kreuz\n",
    "VKK – Verbundkrankenhaus\n",
    "MLK – Malteser Krankenhaus\n",
    "KFO – Kieferorthopädische Fachklinik\n",
    "ZPM – Zentrum für Psychische Gesundheit\n",
    "ZNA – Zentrale Notaufnahme\n",
    "KFH – Kuratorium für Dialyse und Nierentransplantation\n",
    "PKV – Privatklinik für Versicherte\n",
    "\n",
    "e.V. – Eingetragener Verein\n",
    "GmbH – Gesellschaft mit beschränkter Haftung\n",
    "GbR – Gesellschaft bürgerlichen Rechts\n",
    "AG – Aktiengesellschaft\n",
    "OHG – Offene Handelsgesellschaft\n",
    "\n",
    "Preprocessing of Query and Hospital Data\n",
    "Add healthcare:specialty information to hospital data embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import overpy\n",
    "\n",
    "# Initialize the Overpass API\n",
    "api = overpy.Overpass() # Read Only connection to OpenStreetMap\n",
    "\n",
    "# Overpass QL query to get all relevant healthcare facilities in Germany\n",
    "overpass_query = \"\"\"\n",
    "[out:json][timeout:180];\n",
    "area[\"ISO3166-1\"=\"DE\"][admin_level=2];\n",
    "(\n",
    "  // Healthcare facilities\n",
    "  node[\"healthcare\"](area);\n",
    "  way[\"healthcare\"](area);\n",
    "  relation[\"healthcare\"](area);\n",
    ");\n",
    "out body;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the Overpass query\n",
    "result = api.query(overpass_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for node in result.nodes:\n",
    "#     print(node.tags)\n",
    "    \n",
    "#     healthcare:speciality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siebert -> PER\n",
      "Token: Hausarzt, POS: NOUN\n",
      "Token: Dr., POS: NOUN\n",
      "Token: med, POS: PROPN\n",
      "Token: ., POS: PUNCT\n",
      "Token: Siebert, POS: PROPN\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the SpaCy German model for NER\n",
    "nlp = spacy.load(\"de_core_news_lg\") # python -m spacy download de_dep_news_trf\n",
    "\n",
    "\n",
    "# Example text\n",
    "text = \"Hausarzt Dr. med. Siebert\"\n",
    "\n",
    "# Process the text with the NER model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the recognized entities and their labels\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} -> {ent.label_}\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}, POS: {token.pos_}\") # POS: NOUN(Common Noun) POS: PROPN (specific Names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
