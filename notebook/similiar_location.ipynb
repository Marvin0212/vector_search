{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# Load hospital Names from a Text File\n",
    "def load_hospital_names(text_file):\n",
    "    with open(text_file, 'r', encoding='utf-8') as f:\n",
    "        hospital_names = [line.strip() for line in f if line.strip()]\n",
    "    return hospital_names\n",
    "\n",
    "# Compute Embeddings\n",
    "def compute_embeddings(model, sentences, batch_size=512):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Computing Embeddings\"):\n",
    "        batch = sentences[i:i+batch_size] # remove alpha numeric?\n",
    "        batch = [remove_non_alphanumeric(name) for name in batch]\n",
    "        emb = model.encode(batch, show_progress_bar=False, convert_to_numpy=True)\n",
    "        embeddings.append(emb)\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings\n",
    "\n",
    "# Fit and Save NearestNeighbors Model\n",
    "# Instance-based learning is a category of machine learning that relies on storing the training data and making predictions based on the direct comparison of new instances with stored data\n",
    "def fit_nearest_neighbors(embeddings, n_neighbors=10, metric='cosine'):\n",
    "    nn_model = NearestNeighbors(n_neighbors=n_neighbors, metric=metric) # non-parametric algorithm used for finding the closest points in a dataset.\n",
    "    nn_model.fit(embeddings) # organizes the embeddings into a structure that allows efficient querying\n",
    "    return nn_model\n",
    "\n",
    "def remove_non_alphanumeric(input_string):\n",
    "    # Use regex to match alphanumeric characters, spaces, points, and commas\n",
    "    return ''.join(re.findall(r'[\\w\\s.,äöüß]', input_string))\n",
    "\n",
    "# Query Function\n",
    "def query_similar_hospitals(target_sentence, model, nn_model, hospital_names, top_k=5):\n",
    "    # Compute embedding for the target sentence\n",
    "    target_embedding = model.encode([remove_non_alphanumeric(target_sentence)], convert_to_numpy=True)\n",
    "    \n",
    "    # Perform similarity search with the specified top_k\n",
    "    distances, indices = nn_model.kneighbors(target_embedding, n_neighbors=top_k)\n",
    "    \n",
    "    # Retrieve the hospital names and their similarity scores\n",
    "    results = []\n",
    "    similarity = []\n",
    "    for idx, distance in zip(indices[0], distances[0]):\n",
    "        hospital = hospital_names[idx]  # Directly use the list of hospital names\n",
    "        similarity_score = 1 - distance  # Convert cosine distance to similarity\n",
    "        results.append(hospital)\n",
    "        similarity.append(float(similarity_score))\n",
    "    return results, similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_path = '/home/mseiferling/vector_search/data/OpenStreetMap_data/Combined_healthcare_facilities.txt' \n",
    "embeddings_path = '/home/mseiferling/vector_search/data/hospital_embeddings.npy'\n",
    "nearest_neighbors_model_path = '/home/mseiferling/vector_search/data/nearest_neighbors_model.joblib'\n",
    "\n",
    "# model\n",
    "embedding_model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "\n",
    "# Check if embeddings and model already exist\n",
    "if os.path.exists(embeddings_path) and os.path.exists(nearest_neighbors_model_path):\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    nn_model = joblib.load(nearest_neighbors_model_path)\n",
    "    model = SentenceTransformer(embedding_model_name)\n",
    "    hospital_names = load_hospital_names(data_path)\n",
    "else:\n",
    "    # Load hospital names\n",
    "    hospital_names = load_hospital_names(data_path)\n",
    "    \n",
    "    # Load embedding model\n",
    "    model = SentenceTransformer(embedding_model_name)\n",
    "    \n",
    "    # Compute embeddings\n",
    "    embeddings = compute_embeddings(model, hospital_names)\n",
    "    \n",
    "    # Save embeddings\n",
    "    np.save(embeddings_path, embeddings)\n",
    "    \n",
    "    # Fit NearestNeighbors model\n",
    "    nn_model = fit_nearest_neighbors(embeddings, n_neighbors=10, metric='cosine')\n",
    "    \n",
    "    # Save NearestNeighbors model\n",
    "    joblib.dump(nn_model, nearest_neighbors_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Querying for top 10 similar hospitals to 'Hausarzt Dr. med. Siebert':\n",
      "\n",
      "Top similar hospitals:\n",
      "Hausarztpraxis Dr. Siegmund (Similarity Score: 0.9301)\n",
      "Hausarztpraxis Dr. Wiese (Similarity Score: 0.8961)\n",
      "Hausarztpraxis Dr. med. Steffen Walther (Similarity Score: 0.8832)\n",
      "Hausarztpraxis Dr. med. Stephan Wismann (Similarity Score: 0.8802)\n",
      "Praxis Dr. Siebecker (Similarity Score: 0.8640)\n",
      "Arztpraxis Dr. med. Sibylle Diessner (Similarity Score: 0.8626)\n",
      "Arztpraxis Dr. med. Christian Siebel (Similarity Score: 0.8604)\n",
      "Hausarztpraxis Dr. Vondung und Kollegen (Similarity Score: 0.8435)\n",
      "Hausarztpraxis Drs. Stütz (Similarity Score: 0.8409)\n",
      "Arzt Drs. Kern & Wappelhorst (Similarity Score: 0.8403)\n",
      "\n",
      "Sampled Hospital: Hausarztpraxis Dr. Wiese\n",
      "Probabilities associated with each hospital:\n",
      "Hausarztpraxis Dr. Siegmund (Probability: 0.0903)\n",
      "Hausarztpraxis Dr. Wiese (Probability: 0.0903)\n",
      "Hausarztpraxis Dr. med. Steffen Walther (Probability: 0.2035)\n",
      "Hausarztpraxis Dr. med. Stephan Wismann (Probability: 0.2035)\n",
      "Arztpraxis Dr. med. Sibylle Diessner (Probability: 0.1276)\n",
      "Arztpraxis Dr. med. Christian Siebel (Probability: 0.1276)\n",
      "Hausarztpraxis Dr. Vondung und Kollegen (Probability: 0.0903)\n",
      "Hausarztpraxis Drs. Stütz (Probability: 0.0668)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "# Load the SpaCy German model for NER and POS tagging\n",
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "\n",
    "# Function to extract proper nouns and named entities\n",
    "def extract_sensitive_data(text):\n",
    "    doc = nlp(text)\n",
    "    unique_substrings = set()\n",
    "\n",
    "    # Extract named entities of type PERSON, ORG, LOC and proper nouns\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"PER\", \"ORG\", \"LOC\"]:  # PERSON, ORGANIZATION, LOCATION\n",
    "            words = ent.text.split()  # Split ent.text into individual words\n",
    "            unique_substrings.update(words) # Add each word to the set\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PROPN\":  # Proper Noun (e.g., specific names)\n",
    "            unique_substrings.add(token.text)\n",
    "\n",
    "    return list(unique_substrings)\n",
    "\n",
    "# Function to normalize Levenshtein distance\n",
    "def normalize_levenshtein_distance(str1, str2):\n",
    "    lev_distance = levenshtein_distance(str1, str2)\n",
    "    max_len = max(len(str1), len(str2))\n",
    "    if max_len == 0:  # To handle edge cases with empty strings\n",
    "        return 0.0\n",
    "    return lev_distance / max_len  # Normalize by dividing by max string length\n",
    "\n",
    "# Function to calculate average Levenshtein distance\n",
    "def calculate_average_distance(target_sensitive_data, sampled_sensitive_data):\n",
    "    total_distance = 0\n",
    "    num_comparisons = len(target_sensitive_data)\n",
    "    \n",
    "    # For each sensitive substring in the target word, find the closest match in the sampled hospital\n",
    "    for target_substring in target_sensitive_data:\n",
    "        min_distance = float('inf')  # Start with a large number\n",
    "        \n",
    "        for sampled_substring in sampled_sensitive_data:\n",
    "            normalized_distance = normalize_levenshtein_distance(target_substring, sampled_substring)\n",
    "            if normalized_distance < min_distance:\n",
    "                min_distance = normalized_distance\n",
    "\n",
    "        # Accumulate the smallest distance for this target substring\n",
    "        total_distance += min_distance\n",
    "\n",
    "    # Calculate the average normalized distance\n",
    "    if num_comparisons == 0:\n",
    "        return 0.0\n",
    "    return 1 - (total_distance / num_comparisons)\n",
    "\n",
    "# List of substrings to search for\n",
    "keywords = [\n",
    "    # Allgemeine Begriffe\n",
    "    \"arzt\", \"ärzt\", \"chirurg\", \"gemeinschaft\", \"klinik\", \"logie\", \"ologe\", \n",
    "    \"medizin\", \"praxis\", \"sanatorium\", \"therapie\", \"ambulanz\", \n",
    "\n",
    "    # Fachrichtungen und Behandlungen\n",
    "    \"anästhesie\", \"augen\", \"cardio\", \"dental\", \"derm\", \"endokrin\", \"gastro\", \"gyn\", \n",
    "    \"hämo\", \"hno\", \"kardio\", \"neuro\", \"onko\", \"optik\", \"ortho\", \"osteo\", \"pathie\", \n",
    "    \"pädie\", \"pneumo\", \"psych\", \"uro\", \"zahn\", \"zähne\",\n",
    "\n",
    "    # Verfahren und Diagnostik\n",
    "    \"blut\", \"ct\", \"diagnostik\", \"echo\", \"labor\", \"mrt\", \"radio\", \"rehabil\", \"spende\",\n",
    "\n",
    "    # Pflege und Behandlungsarten\n",
    "    \"betreuung\", \"ernährung\", \"geriatr\", \"hospiz\", \"intensiv\", \"palliativ\", \"pflege\", \n",
    "    \"physio\", \"rehaklinik\", \"therapeut\",\n",
    "\n",
    "    # Alternative Medizin\n",
    "    \"akupunkt\", \"heilpraktiker\", \"homöo\", \"naturheil\",\n",
    "\n",
    "    # Einrichtungen und Zentren\n",
    "    \"fach\", \"kranken\", \"notfall\", \"reha\", \"zentrum\", \"haus\", \"test\",\n",
    "\n",
    "    # Pädiatrie, Frauen und Spezialversorgung\n",
    "    \"diabetes\", \"frauen\", \"kinder\", \"lungen\",\n",
    "\n",
    "    # Zusätzliche Begriffe\n",
    "    \"apotheke\", \"behandl\", \"chirurgi\", \"gesundheitszentrum\", \n",
    "    \"klinisch\", \"untersuch\",\n",
    "    \n",
    "    # titel\n",
    "    \"dr\",\"phil\",\"univ\",\"medic\",\"dres\",\"med\",\"dipl\",\"psych\",\"dent\",\"vet\",\n",
    "]\n",
    "\n",
    "target_hospital = \"Hausarzt Dr. med. Siebert\"\n",
    "top_k = 10\n",
    "\n",
    "print(f\"\\nQuerying for top {top_k} similar hospitals to '{target_hospital}':\")\n",
    "similar_hospitals, similarity_scores = query_similar_hospitals(\n",
    "    target_hospital, model, nn_model, hospital_names, top_k=top_k\n",
    ")\n",
    "\n",
    "# Exclude exact matches (similarity score of 1)\n",
    "filtered_hospitals = [\n",
    "    hospital for hospital, score in zip(similar_hospitals, similarity_scores) \n",
    "    if score != 1\n",
    "]\n",
    "\n",
    "print(\"\\nTop similar hospitals:\")\n",
    "for hospital, score in zip(filtered_hospitals, similarity_scores):\n",
    "    print(f\"{hospital} (Similarity Score: {score:.4f})\")\n",
    "\n",
    "# Extract sensitive words from the target hospital name\n",
    "extracted_sensitive_words = extract_sensitive_data(target_hospital)\n",
    "\n",
    "# Remove sensitive words that falsely contain healthcare keywords\n",
    "filtered_sensitive_words = [\n",
    "    word for word in extracted_sensitive_words \n",
    "    if not any(keyword in word.lower() for keyword in keywords)\n",
    "]\n",
    "\n",
    "# Exclude hospitals containing any of the filtered sensitive words\n",
    "filtered_hospitals = [\n",
    "    hospital for hospital in filtered_hospitals \n",
    "    if not any(sensitive_word in hospital.lower() for sensitive_word in filtered_sensitive_words)\n",
    "]\n",
    "\n",
    "# Identify healthcare-related words in the target hospital name\n",
    "healthcare_terms = [\n",
    "    word for word in target_hospital.split() \n",
    "    if any(keyword in word.lower() for keyword in keywords)\n",
    "]\n",
    "\n",
    "ranked_hospitals = []\n",
    "\n",
    "# Calculate average normalized Levenshtein distance and filter hospitals\n",
    "for hospital in filtered_hospitals:\n",
    "    avg_distance = calculate_average_distance(healthcare_terms, hospital.split())\n",
    "    if avg_distance >= 0.5:\n",
    "        ranked_hospitals.append((hospital, avg_distance))\n",
    "\n",
    "# Proceed only if there are ranked hospitals\n",
    "if ranked_hospitals:\n",
    "    distances = np.array([distance for _, distance in ranked_hospitals])\n",
    "\n",
    "    # Apply sigmoid function to distances\n",
    "    sigmoid_distances = 1 / (1 + np.exp(-distances))\n",
    "\n",
    "    # Apply temperature scaling to make the distribution sharper\n",
    "    temperature = 0.1\n",
    "    scaled_scores = sigmoid_distances ** (1 / temperature)\n",
    "\n",
    "    # Normalize the scaled scores to create a probability distribution\n",
    "    probabilities = scaled_scores / np.sum(scaled_scores)\n",
    "\n",
    "    # Sample one hospital based on the computed probabilities\n",
    "    sampled_hospital = np.random.choice(\n",
    "        [hospital for hospital, _ in ranked_hospitals],\n",
    "        p=probabilities\n",
    "    )\n",
    "\n",
    "    # Display the sampled hospital and associated probabilities\n",
    "    print(f\"\\nSampled Hospital: {sampled_hospital}\")\n",
    "    print(\"Probabilities associated with each hospital:\")\n",
    "    for (hospital, _), probability in zip(ranked_hospitals, probabilities):\n",
    "        print(f\"{hospital} (Probability: {probability:.4f})\")\n",
    "else:\n",
    "    print(\"\\nNo hospitals met the distance criteria.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the following steps ensure no sensitive information is disclosed\n",
    "step 1: remove 1:1 similarity \n",
    "\n",
    "step 2: detect sensitive names using a POS Tagger model from spacy which can detect pROPER NOUNS\n",
    "step 3: remove query results containing THESE sensitve proper noun names\n",
    "\n",
    "# the following steps serve two purposes it increases the likelihood of semantic similiar surrogate and it ensures that the similarity in those top names is based on the healthcare facility and not on the sensitve information decreasing likelihood of choosing sensitive surrogate\n",
    "step 4: detect healthcare names with a list of facility keywords \n",
    "step 5: get top levenshtein distance names with the lowest distance from the query \n",
    "\n",
    "# picking the surrogate\n",
    "step 6: sample from the remaining results which exclude results with sensitve proper nouns and prioritize results with low levenshtein distance to the semnatic relevant healthcase facility names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Between Semantic Similarity Approach and Random Sampling:\n",
    "\n",
    "**Objective:**\n",
    "To demonstrate that using a semantic similarity-based approach for data extraction—specifically for identifying and preserving the meaning of semantic categories like \"hospital\"—is more effective than random sampling, both in terms of preserving utility and maintaining anonymity.\n",
    "\n",
    "**Approach:**\n",
    "\n",
    "1. **Semantic Similarity Approach:**\n",
    "   - **Keyword-Based Selection:** Using predefined keywords to generate a list of semantically related hospitals.\n",
    "   - **Annotation and Marking:** Identifying and marking terms that semantically relate to hospitals within the dataset.\n",
    "   - **Preservation of Meaning:** Ensuring that terms related to the \"hospital\" category retain their semantic information during data selection or anonymization.\n",
    "\n",
    "2. **Random Sampling Approach:**\n",
    "   - **Random Selection:** Extracting a random subset of the dataset without considering semantic similarity.\n",
    "   - **Loss of Information:** Risk of losing key terms or relationships that are important to the category \"hospital,\" resulting in decreased utility.\n",
    "\n",
    "---\n",
    "anonymity and utility evaluation\n",
    "utility - preserve semantic meaning?\n",
    "anonymity - if one is sampled how likely is it to sample the original one again? \n",
    "-------\n",
    "Könnten Stations namen in Hospital Location Annotation vorkommen? \n",
    "Falls ja wäre das nicht vom jetztigen datensatz abgedeckt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FA – Facharzt\n",
    "Gyn – Gynäkologe: \n",
    "Uro – Urologe: \n",
    "Derm – Dermatologe: \n",
    "Päd – Pädiater: \n",
    "Radi – Radiologe: \n",
    "Neuro – Neurologe: \n",
    "Psych – Psychologe\n",
    "ZA - Zahnarzt\n",
    "\n",
    "KH – Krankenhaus\n",
    "LKH - Landeskrankenhaus\n",
    "MVZ – Medizinisches Versorgungszentrum\n",
    "ZMVZ - Zahnmedizinisches Versorgungszentrum \n",
    "PHV - patientenheimversorgung\n",
    "ZAR - Zentrum für ambulante Rehabilitation\n",
    "KJPP - Kinder- und Jugendpsychiatrie und Psychotherapie\n",
    "UK – Universitätsklinikum\n",
    "BG – Berufsgenossenschaftliches Krankenhaus\n",
    "REHA – Rehabilitationsklinik\n",
    "KHB – Krankenhausbetriebsgesellschaft\n",
    "SPZ – Sozialpädiatrisches Zentrum\n",
    "EVK – Evangelisches Krankenhaus\n",
    "CVK – Christliches Krankenhaus\n",
    "DRK – Deutsches Rotes Kreuz\n",
    "VKK – Verbundkrankenhaus\n",
    "MLK – Malteser Krankenhaus\n",
    "KFO – Kieferorthopädische Fachklinik\n",
    "ZPM – Zentrum für Psychische Gesundheit\n",
    "ZNA – Zentrale Notaufnahme\n",
    "KFH – Kuratorium für Dialyse und Nierentransplantation\n",
    "PKV – Privatklinik für Versicherte\n",
    "\n",
    "Preprocessing of Query and Hospital Data\n",
    "Add healthcare:specialty information to hospital data embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import overpy\n",
    "\n",
    "# Initialize the Overpass API\n",
    "api = overpy.Overpass() # Read Only connection to OpenStreetMap\n",
    "\n",
    "# Overpass QL query to get all relevant healthcare facilities in Germany\n",
    "overpass_query = \"\"\"\n",
    "[out:json][timeout:180];\n",
    "area[\"ISO3166-1\"=\"DE\"][admin_level=2];\n",
    "(\n",
    "  // Healthcare facilities\n",
    "  node[\"healthcare\"](area);\n",
    "  way[\"healthcare\"](area);\n",
    "  relation[\"healthcare\"](area);\n",
    ");\n",
    "out body;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the Overpass query\n",
    "result = api.query(overpass_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for node in result.nodes:\n",
    "#     print(node.tags)\n",
    "    \n",
    "#     healthcare:speciality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siebert -> PER\n",
      "Token: Hausarzt, POS: NOUN\n",
      "Token: Dr., POS: NOUN\n",
      "Token: med, POS: PROPN\n",
      "Token: ., POS: PUNCT\n",
      "Token: Siebert, POS: PROPN\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the SpaCy German model for NER\n",
    "nlp = spacy.load(\"de_core_news_lg\") # python -m spacy download de_dep_news_trf\n",
    "\n",
    "\n",
    "# Example text\n",
    "text = \"Hausarzt Dr. med. Siebert\"\n",
    "\n",
    "# Process the text with the NER model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the recognized entities and their labels\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} -> {ent.label_}\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}, POS: {token.pos_}\") # POS: NOUN(Common Noun) POS: PROPN (specific Names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
